{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b319759-69fc-4598-a4dc-45c535855383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "sc.settings.set_figure_params(dpi=100)\n",
    "print(sc.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a6f3b-562e-4b81-b472-bf341a147e28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import blosum as bl\n",
    "# perform encoding by direct, BCP, BLOSUM\n",
    "vocab = ['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','Y']\n",
    "# direct encoding\n",
    "map_direct = {x:[1 * (x == y) for y in vocab] for x in vocab}\n",
    "# bcp encoding\n",
    "aa_hydrophobicity = {\n",
    "    'A': 1.8,  # Alanine\n",
    "    'R': -4.5,  # Arginine\n",
    "    'N': -3.5,  # Asparagine\n",
    "    'D': -3.5,  # Aspartic Acid\n",
    "    'C': 2.5,  # Cysteine\n",
    "    'E': -3.5,  # Glutamic Acid\n",
    "    'Q': -3.5,  # Glutamine\n",
    "    'G': -0.4,  # Glycine\n",
    "    'H': -3.2,  # Histidine\n",
    "    'I': 4.5,  # Isoleucine\n",
    "    'L': 3.8,  # Leucine\n",
    "    'K': -3.9,  # Lysine\n",
    "    'M': 1.9,  # Methionine\n",
    "    'F': 2.8,  # Phenylalanine\n",
    "    'P': -1.6,  # Proline\n",
    "    'S': -0.8,  # Serine\n",
    "    'T': -0.7,  # Threonine\n",
    "    'W': -0.9,  # Tryptophan\n",
    "    'Y': -1.3,  # Tyrosine\n",
    "    'V': 4.2,  # Valine\n",
    "}\n",
    "# https://www.imgt.org/IMGTeducation/Aide-memoire/_UK/aminoacids/IMGTclasses.html\n",
    "aa_volume = {\n",
    "    'A': 88.6,   # Alanine\n",
    "    'R': 173.4,  # Arginine\n",
    "    'N': 114.1,  # Asparagine\n",
    "    'D': 111.1,  # Aspartic Acid\n",
    "    'C': 108.5,  # Cysteine\n",
    "    'E': 138.4,  # Glutamic Acid\n",
    "    'Q': 143.8,  # Glutamine\n",
    "    'G': 60.1,   # Glycine\n",
    "    'H': 153.2,  # Histidine\n",
    "    'I': 166.7,  # Isoleucine\n",
    "    'L': 166.7,  # Leucine\n",
    "    'K': 168.6,  # Lysine\n",
    "    'M': 162.9,  # Methionine\n",
    "    'F': 189.9,  # Phenylalanine\n",
    "    'P': 112.7,  # Proline\n",
    "    'S': 89.0,   # Serine\n",
    "    'T': 116.1,  # Threonine\n",
    "    'W': 227.8,  # Tryptophan\n",
    "    'Y': 193.6,  # Tyrosine\n",
    "    'V': 140.0,  # Valine\n",
    "}\n",
    "# 1 = donor and acceptor, 0.5 = only donor or acceptor\n",
    "aa_hbond = {\n",
    "    'A': 0,    # Alanine\n",
    "    'R': 0.5,  # Arginine\n",
    "    'N': 1,    # Asparagine\n",
    "    'D': 0.5,  # Aspartic Acid\n",
    "    'C': 0,    # Cysteine\n",
    "    'E': 0.5,  # Glutamic Acid\n",
    "    'Q': 1,    # Glutamine\n",
    "    'G': 0,    # Glycine\n",
    "    'H': 1,    # Histidine\n",
    "    'I': 0,    # Isoleucine\n",
    "    'L': 0,    # Leucine\n",
    "    'K': 0.5,  # Lysine\n",
    "    'M': 0,    # Methionine\n",
    "    'F': 0,    # Phenylalanine\n",
    "    'P': 0,    # Proline\n",
    "    'S': 1,    # Serine\n",
    "    'T': 1,    # Threonine\n",
    "    'W': 0.5,  # Tryptophan\n",
    "    'Y': 1,    # Tyrosine\n",
    "    'V': 0,    # Valine\n",
    "}\n",
    "has_sulfur = ['C','M']\n",
    "is_aromatic = ['F','Y','W']\n",
    "is_aliphatic = ['A','G','I','L','P','V']\n",
    "is_basic = ['R','H','K']\n",
    "is_acidic = ['D','E']\n",
    "has_amide = ['N','Q']\n",
    "vocab_bcp = ['hydrophobicity','volume','hbond','has_sulfur','is_aromatic',\n",
    "             'is_aliphatic','is_basic','is_acidic','has_amide']\n",
    "# > define a method to return the embedding for a given amino acid in BCP space\n",
    "def bcp_translation(aa):\n",
    "    embedding = []\n",
    "    embedding.append(aa_hydrophobicity[aa])\n",
    "    embedding.append(aa_volume[aa])\n",
    "    embedding.append(aa_hbond[aa])\n",
    "    embedding.append(1 * (aa in has_sulfur))\n",
    "    embedding.append(1 * (aa in is_aromatic))\n",
    "    embedding.append(1 * (aa in is_aliphatic))\n",
    "    embedding.append(1 * (aa in is_basic))\n",
    "    embedding.append(1 * (aa in is_acidic))\n",
    "    embedding.append(1 * (aa in has_amide))\n",
    "    return embedding\n",
    "map_bcp = {x:bcp_translation(x) for x in vocab}\n",
    "# blosum encoding\n",
    "map_blosum = {x:[bl.BLOSUM(62)[x][y] for y in vocab] for x in vocab}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb71ea3-9864-4f64-a35a-fb67fc8a75f2",
   "metadata": {},
   "source": [
    "### Read in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e7ea60-0977-423c-875a-9861e89327c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in the data\n",
    "df = pd.read_csv('../outs/df.int.clean.csv', index_col=0)\n",
    "a_trb = sc.read_h5ad('../outs/adata.trb.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984b22b8-76e1-49ea-9951-41eda0de7d37",
   "metadata": {},
   "source": [
    "### kNN Model to Map Sampled Z Coordinates to UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5257b-9708-4f9f-bd54-37da8e011cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# rough mapping of UMAP via kNN\n",
    "neigh = KNeighborsRegressor(n_neighbors=5)\n",
    "neigh.fit(a_trb.X, a_trb.obsm['X_umap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad7afa-4233-4215-903a-d12c0feebea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "# validate\n",
    "np.random.seed(0)\n",
    "idxs = np.random.choice(a_trb.obs.index, size=1000, replace=False)\n",
    "fig, ax = plt.subplots(); ax.grid(False)\n",
    "x, y = neigh.predict(a_trb[idxs].X)[:, 0], a_trb[idxs].obsm['X_umap'][:, 0]\n",
    "ax.scatter(x, y, color='dodgerblue', s=5, alpha=0.25)\n",
    "xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
    "# model the lines\n",
    "model = np.polynomial.Polynomial(0)\n",
    "model = model.fit(x, y, 1)\n",
    "xl, yl = model.linspace(domain=xlim)\n",
    "ax.plot(xl, yl, color='k', linestyle='--')\n",
    "ax.set_xlim(*xlim); ax.set_ylim(*ylim)\n",
    "ax.set(xlabel='Predicted UMAP 1', ylabel='True UMAP 1')\n",
    "ss.pearsonr(x, y), root_mean_squared_error(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6551c55d-4638-44fc-b643-2b275790a238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check the difference\n",
    "ys = []\n",
    "for seed in range(5):\n",
    "    np.random.seed(seed)\n",
    "    idxs = np.random.choice(a_trb.obs.index, size=1000, replace=False)\n",
    "    x, y = neigh.predict(a_trb[idxs].X)[:, 0], a_trb[idxs].obsm['X_umap'][:, 0]\n",
    "    ys.append(root_mean_squared_error(x, y))\n",
    "fig, ax = plt.subplots(figsize=[1.5, 4]); ax.grid(False)\n",
    "sns.boxplot(y=ys, linewidth=1.5, saturation=1, showfliers=False, linecolor='dodgerblue', color='skyblue')\n",
    "sns.stripplot(y=ys, linewidth=1.5, s=6, alpha=0.5, color='skyblue', edgecolor='dodgerblue')\n",
    "ax.set_xlim(-1, 1); ax.set_ylabel('RMSE UMAP 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0630e62-829e-4261-be1e-df54280b95e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# validate\n",
    "np.random.seed(0)\n",
    "idxs = np.random.choice(a_trb.obs.index, size=1000)\n",
    "fig, ax = plt.subplots(); ax.grid(False)\n",
    "x, y = neigh.predict(a_trb[idxs].X)[:, 1], a_trb[idxs].obsm['X_umap'][:, 1]\n",
    "ax.scatter(x, y, color='dodgerblue', s=5, alpha=0.25)\n",
    "xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
    "# model the lines\n",
    "model = np.polynomial.Polynomial(0)\n",
    "model = model.fit(x, y, 1)\n",
    "xl, yl = model.linspace(domain=xlim)\n",
    "ax.plot(xl, yl, color='k', linestyle='--')\n",
    "ax.set_xlim(*xlim); ax.set_ylim(*ylim)\n",
    "ax.set(xlabel='Predicted UMAP 2', ylabel='True UMAP 2')\n",
    "ss.pearsonr(x, y), root_mean_squared_error(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c5dec-fc5c-479e-a6d1-c7d1097038e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check the difference\n",
    "ys = []\n",
    "for seed in range(5):\n",
    "    np.random.seed(seed)\n",
    "    idxs = np.random.choice(a_trb.obs.index, size=1000, replace=False)\n",
    "    x, y = neigh.predict(a_trb[idxs].X)[:, 1], a_trb[idxs].obsm['X_umap'][:, 1]\n",
    "    ys.append(root_mean_squared_error(x, y))\n",
    "fig, ax = plt.subplots(figsize=[1.5, 4]); ax.grid(False)\n",
    "sns.boxplot(y=ys, linewidth=1.5, saturation=1, showfliers=False, linecolor='dodgerblue', color='skyblue')\n",
    "sns.stripplot(y=ys, linewidth=1.5, s=6, alpha=0.5, color='skyblue', edgecolor='dodgerblue')\n",
    "ax.set_xlim(-1, 1); ax.set_ylabel('RMSE UMAP 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfdcc81-3d29-4144-a8a5-ddf7737f6ce6",
   "metadata": {},
   "source": [
    "### AgFlow Model Based on Normalizing Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e94e6a7-569d-4291-9676-d6b1aafe0961",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://paperswithcode.com/paper/density-estimation-using-real-nvp\n",
    "# https://colab.research.google.com/github/senya-ashukha/real-nvp-pytorch/blob/master/real-nvp-pytorch.ipynb#scrollTo=nKXQrDNFZG8D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d093b489-96da-4bed-b038-d6ea2e1bc315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.nn.parameter import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f01a22d-a715-49aa-90c3-797d0bd0a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the realNVP module from literature\n",
    "class RealNVP(nn.Module):\n",
    "    def __init__(self, nets, nett, mask, prior):\n",
    "        super(RealNVP, self).__init__()\n",
    "        \n",
    "        self.prior = prior\n",
    "        self.mask = nn.Parameter(mask, requires_grad=False)\n",
    "        self.t = torch.nn.ModuleList([nett() for _ in range(len(masks))])\n",
    "        self.s = torch.nn.ModuleList([nets() for _ in range(len(masks))])\n",
    "        \n",
    "    def g(self, z):\n",
    "        x = z\n",
    "        for i in range(len(self.t)):\n",
    "            x_ = x * self.mask[i]\n",
    "            s = self.s[i](x_) * (1 - self.mask[i])\n",
    "            t = self.t[i](x_) * (1 - self.mask[i])\n",
    "            x = x_ + (1 - self.mask[i]) * (x * torch.exp(s) + t)\n",
    "        return x\n",
    "\n",
    "    def f(self, x):\n",
    "        log_det_J, z = x.new_zeros(x.shape[0]), x\n",
    "        for i in reversed(range(len(self.t))):\n",
    "            z_ = self.mask[i] * z\n",
    "            s = self.s[i](z_) * (1 - self.mask[i])\n",
    "            t = self.t[i](z_) * (1 - self.mask[i])\n",
    "            z = (1 - self.mask[i]) * (z - t) * torch.exp(-s) + z_\n",
    "            log_det_J -= s.sum(dim=1)\n",
    "        return z, log_det_J\n",
    "    \n",
    "    def log_prob(self,x):\n",
    "        z, logp = self.f(x)\n",
    "        return self.prior.log_prob(z) + logp\n",
    "        \n",
    "    def sample(self, batchSize): \n",
    "        z = self.prior.sample((batchSize, 1))\n",
    "        logp = self.prior.log_prob(z)\n",
    "        x = self.g(z)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc85eaa-67ed-42c5-abcf-9059d22d45a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 256 stands for the quantization I believe, the mask is a checkerboard type\n",
    "nets = lambda: nn.Sequential(nn.Linear(32, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 32), nn.Tanh()).to('cuda')\n",
    "nett = lambda: nn.Sequential(nn.Linear(32, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 32)).to('cuda')\n",
    "masks = torch.from_numpy(np.array([[0, 1]*16, [1, 0]*16] * 4).astype(np.float32)).to('cuda')\n",
    "prior = distributions.MultivariateNormal(torch.zeros(32).to('cuda'), torch.eye(32).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec27012-3c4d-4638-95eb-c6ccb738670a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "torch.manual_seed(0); np.random.seed(0)\n",
    "flow = RealNVP(nets, nett, masks, prior)\n",
    "optimizer = torch.optim.Adam([p for p in flow.parameters() if p.requires_grad==True], lr=1e-5)\n",
    "# derive the mapping dataset\n",
    "trbs = df.loc[df['AG'] == 'YLQPRTFLL', 'TRB']\n",
    "trbs = trbs[trbs.isin(a_trb.obs.index)]\n",
    "X = a_trb[trbs].X.astype(np.float32).copy()\n",
    "# track the loss values\n",
    "losses = []\n",
    "for t in range(10001):\n",
    "    # derive the loss\n",
    "    loss = -flow.log_prob(torch.from_numpy(X).to('cuda')).mean()\n",
    "    # optimize accordingly\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    if t % 1000 == 0:\n",
    "        print('iter %s:' % t, 'loss = %.3f' % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdcc380-16c9-4fb6-a607-612219eaf9c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the loss curve\n",
    "fig, ax = plt.subplots(); ax.grid(False)\n",
    "ax.plot(losses, color='dodgerblue')\n",
    "ax.set(xlabel='Epochs', ylabel='Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78c669b-2d4d-40ea-be45-8cc1b116a627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample from the dataset\n",
    "torch.manual_seed(0); np.random.seed(0)\n",
    "x = flow.sample(1000).clone().cpu().detach().numpy()\n",
    "umap = neigh.predict(x[:, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0b3448-d01e-4f9c-8962-4ee56a7e23b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# derive the predicted\n",
    "fig, ax = plt.subplots(); ax.grid(False)\n",
    "ax.scatter(a_trb.obsm['X_umap'][:, 0], a_trb.obsm['X_umap'][:, 1], s=0.0001, color='lightgray')\n",
    "z = ss.gaussian_kde(umap.T)(umap.T); idxs = np.argsort(z)\n",
    "ax.scatter(umap[idxs, 0], umap[idxs, 1], c=z[idxs], alpha=0.5, s=4, cmap='Blues')\n",
    "ax.set_title(r'$\\hat{x} = g(z)$')\n",
    "\n",
    "# derive the ground truth\n",
    "# compare with the known\n",
    "fig, ax = plt.subplots(); ax.grid(False)\n",
    "ax.scatter(a_trb.obsm['X_umap'][:, 0], a_trb.obsm['X_umap'][:, 1], s=0.0001, color='lightgray')\n",
    "z = ss.gaussian_kde(a_trb[trbs].obsm['X_umap'].T)(a_trb[trbs].obsm['X_umap'].T); idxs = np.argsort(z)\n",
    "ax.scatter(a_trb[trbs].obsm['X_umap'][idxs, 0], a_trb[trbs].obsm['X_umap'][idxs, 1], c=z[idxs], alpha=0.5, s=4, cmap='Blues')\n",
    "ax.set_title(r'$x$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf6eb6-87a5-48d5-9b04-edfbb27d381f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Statistically Examine AgFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cfce8f-e82c-4ab1-aac8-fb31ddbdb259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statsmodels as sm\n",
    "# look at the range of pvalues\n",
    "pvals = []\n",
    "for idx in range(a_trb.shape[1]):\n",
    "    p = ss.ks_2samp(x[:, 0, idx], a_trb[trbs].X[:, idx], alternative='two-sided')[1]\n",
    "    pvals.append(p)\n",
    "pvals_truth = pvals\n",
    "# compare against a random subset\n",
    "np.random.seed(0)\n",
    "trbs_rand = np.random.choice(a_trb.obs.index, size=len(trbs) * 3, replace=True)\n",
    "pvals = []\n",
    "for idx in range(a_trb.shape[1]):\n",
    "    p = ss.ks_2samp(x[:, 0, idx], a_trb[trbs_rand].X[:, idx], alternative='two-sided')[1]\n",
    "    pvals.append(p)\n",
    "pvals_rand = pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfd2bc0-e60e-4bae-93d2-7f7f9509786f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compare the p-value for the Kolmogorov-Smirnov\n",
    "xs = ['Truth']*len(pvals_truth)+['Rand']*len(pvals_rand)\n",
    "ys = -np.log10(pvals_truth + pvals_rand)\n",
    "fig, ax = plt.subplots(figsize=[2, 4]); ax.grid(False)\n",
    "sns.boxplot(x=xs, y=ys, linewidth=1.5, saturation=1, showfliers=False, linecolor='dodgerblue', color='skyblue',\n",
    "            order=['Rand','Truth'], palette=['lightgray','skyblue'])\n",
    "np.random.seed(0)\n",
    "sns.stripplot(x=xs, y=ys, jitter=0.4, palette=['dodgerblue'], order=['Truth'], alpha=0.4, s=4)\n",
    "sns.stripplot(x=xs, y=ys, jitter=0.4, palette=['grey'], order=['Rand'], alpha=0.4, s=4)\n",
    "ax.set_xlim(-1, 2); ax.set_ylabel('-log$_{10}$(p-value)\\nKS test for CDF difference')\n",
    "ax.get_children()[0].set_hatch('//')\n",
    "ax.get_children()[0].set_edgecolor('grey')\n",
    "for idx in range(1, 6):\n",
    "    ax.get_children()[idx].set_color('grey')\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.set_xticklabels(['Model\\nvs. Rand','Model\\nvs. Truth'])\n",
    "ss.mannwhitneyu(pvals_truth, pvals_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2df728-a332-4ba2-be8b-f7925f6489e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compare with FDR\n",
    "xs, ys, zs = [], [], []\n",
    "xticklabels_mw, xticklabels_ks = [], []\n",
    "for idx in range(a_trb.shape[1]):\n",
    "    ys1, ys2, ys3 = x[:, 0, idx].tolist(), a_trb[trbs].X[:, idx].tolist(), a_trb[trbs_rand].X[:, idx].tolist()\n",
    "    ys_iter = ys1 + ys2 + ys3; ys += ys_iter\n",
    "    xs_iter = ['Model']*len(ys1) + ['Truth']*len(ys2) + ['Rand']*len(ys3); xs += xs_iter\n",
    "    zs += [idx] * len(xs_iter)\n",
    "    \n",
    "# create the plot with mann-whitneyu\n",
    "fig, ax = plt.subplots(figsize=[20, 4]); ax.grid(False)\n",
    "sns.boxplot(x=zs, y=ys, hue=xs, linewidth=1.5, saturation=1, showfliers=False, linecolor='dodgerblue', color='skyblue',\n",
    "            hue_order=['Rand','Truth','Model'], palette=['lightgray','lightsteelblue','skyblue'])\n",
    "ax.set_xlim(-1, a_trb.shape[1])\n",
    "ax.set_xticklabels([int(float(x.get_text()))+1 for x in ax.get_xticklabels()])\n",
    "ax.set_yticks(np.arange(-3, 3+1, 1))\n",
    "ax.set_yticklabels([x.get_text() for x in ax.get_yticklabels()], rotation=90)\n",
    "ax.set_xlabel('Tarpon Latent Dimension', rotation=180)\n",
    "ax.set_ylabel('Latent Dimension Value\\n(Arbitary Units)')\n",
    "shift = 5\n",
    "for idx in range(a_trb.shape[1]):\n",
    "    ax.get_children()[idx+idx*shift].set_hatch('//')\n",
    "    ax.get_children()[idx+idx*shift].set_edgecolor('grey')\n",
    "    for idx in range(idx+idx*shift+1, idx+idx*shift+6):\n",
    "        ax.get_children()[idx].set_color('grey')\n",
    "shift_ = 6*a_trb.shape[1]\n",
    "for idx in range(a_trb.shape[1]):\n",
    "    ax.get_children()[shift_+idx+idx*shift].set_hatch('/')\n",
    "    ax.get_children()[shift_+idx+idx*shift].set_edgecolor('navy')\n",
    "    for idx in range(shift_+idx+idx*shift+1, shift_+idx+idx*shift+6):\n",
    "        ax.get_children()[idx].set_color('navy')\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.legend('', frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe032c-e4f1-401e-824a-774b1a4e3b57",
   "metadata": {},
   "source": [
    "### Convert Z Coordinates to Sequence to Compare Overlap in Repertoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fee3db-db0b-41bd-8a4d-c8766d5e88ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read back in the original TRB solver\n",
    "# define the key parameters\n",
    "init_embed_size = 50-1\n",
    "protein_len = 48\n",
    "init_kernel_size = 3\n",
    "init_cnn_filters = 256\n",
    "init_kernel_stride = 1\n",
    "init_kernel_padding = 1\n",
    "secn_cnn_filters = 256\n",
    "latent_dim = 32\n",
    "vocab = ['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','Y']\n",
    "# we want the embedding output to be the vocab with the length to allow for reconstruction\n",
    "out_embed_size = len(vocab)\n",
    "n_nodes_len = 32\n",
    "\n",
    "# define the convolutional variational autoencoder\n",
    "class ConvVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvVAE, self).__init__()\n",
    "\n",
    "        # encoding\n",
    "        self.fc1 = nn.Conv1d(\n",
    "            in_channels=init_embed_size, out_channels=init_cnn_filters, kernel_size=init_kernel_size, \n",
    "            stride=init_kernel_stride, padding=init_kernel_padding,\n",
    "        )\n",
    "        self.fc2 = nn.Conv1d(\n",
    "            in_channels=init_cnn_filters, out_channels=secn_cnn_filters, kernel_size=init_kernel_size, \n",
    "            stride=init_kernel_stride, padding=init_kernel_padding\n",
    "        )\n",
    "        # variational sampling\n",
    "        self.fc31 = nn.Linear(secn_cnn_filters*protein_len, latent_dim)\n",
    "        self.fc32 = nn.Linear(secn_cnn_filters*protein_len, latent_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim, secn_cnn_filters*protein_len)\n",
    "        # decoding\n",
    "        self.fc5 = nn.ConvTranspose1d(\n",
    "            in_channels=secn_cnn_filters, out_channels=init_cnn_filters, kernel_size=init_kernel_size, \n",
    "            stride=init_kernel_stride, padding=init_kernel_padding\n",
    "        )\n",
    "        self.fc6 = nn.ConvTranspose1d(\n",
    "            in_channels=init_cnn_filters, out_channels=out_embed_size, kernel_size=init_kernel_size, \n",
    "            stride=init_kernel_stride, padding=init_kernel_padding\n",
    "        )\n",
    "        self.fc7 = nn.Linear(init_cnn_filters*protein_len, n_nodes_len)\n",
    "        self.fc8 = nn.Linear(n_nodes_len, 1)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x1 = nn.LeakyReLU()(self.fc1(x[:, :-1, :]))\n",
    "        x2 = nn.LeakyReLU()(self.fc2(x1))\n",
    "        x2_ = nn.Flatten()(x2)\n",
    "        return self.fc31(x2_), self.fc32(x2_)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        x4 = nn.LeakyReLU()(self.fc4(z))\n",
    "        x4_ = x4.view(-1, secn_cnn_filters, protein_len)\n",
    "        x5 = nn.LeakyReLU()(self.fc5(x4_))\n",
    "        x5_ = nn.Flatten()(x5)\n",
    "        x6 = nn.Sigmoid()(self.fc6(x5))\n",
    "        return x6, self.fc8(nn.LeakyReLU()(self.fc7(x5_)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "# load the model\n",
    "model = ConvVAE().to('cuda')\n",
    "model.load_state_dict(torch.load('../models/model.convvae.trb.torch', weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8663c737-e730-4d9c-bafd-d94e579cd13d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define an engine to derive sequence\n",
    "def engine(model, z):\n",
    "    # derive the embedding and length\n",
    "    tmp_out, tmp_len = model.decode(z)\n",
    "    tmp_out = tmp_out.clone().detach().cpu().numpy()\n",
    "    tmp_len = tmp_len.clone().detach().cpu().numpy()\n",
    "    tmp_out = tmp_out[0]; tmp_len = round(tmp_len[0][0])\n",
    "    \n",
    "    # interpolate back to a sequence using the length\n",
    "    curr_len = 48; targ_len = tmp_len\n",
    "    # compute the x-coordinates of the original\n",
    "    xp = np.arange(curr_len) / (curr_len - 1)\n",
    "    x = np.arange(targ_len) / (targ_len - 1)\n",
    "    # interpolate the results\n",
    "    res = np.array([np.interp(x, xp, tmp_out[idx, :]) for idx in range(tmp_out.shape[0])])\n",
    "\n",
    "    # derive the sequence\n",
    "    data = pd.DataFrame(res.T, columns=vocab).T\n",
    "    return ''.join(data.idxmax(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ecedae-b8e8-4c9c-801e-12493cbd4f1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# attempt to generate some peptides\n",
    "seqs = []\n",
    "for idx in tqdm(range(x.shape[0]), total=x.shape[0]):\n",
    "    seqs.append(engine(model, torch.from_numpy(x[idx, 0, :].astype(np.float32)).to('cuda')))\n",
    "seqs = pd.Series(seqs)\n",
    "\n",
    "# hypergeometric where you have M animals, n are dogs, then you choose a random N from the M animals how many are dogs\n",
    "# in our scenario this is where we have the entire TCRbeta-ome supplemented with generated samples\n",
    "M  = a_trb.shape[0] + len(seqs[~seqs.isin(a_trb.obs.index)].unique())\n",
    "n = len(trbs.unique())\n",
    "N = len(seqs.unique())\n",
    "k = len(set(trbs) & set(seqs))\n",
    "# define the distribution\n",
    "fig, ax = plt.subplots(figsize=[4, 2]); ax.grid(False)\n",
    "xl = np.arange(0, 26, 1)\n",
    "yl = ss.hypergeom(M, n, N).pmf(xl)\n",
    "ax.plot(xl, yl*100, color='grey', linestyle='--')\n",
    "ax.axvline(k, color='dodgerblue', lw=2)\n",
    "ax.set(xlabel='# of Overlapping Unique TCRs', ylabel='Probability', title='Peptide-Specific TCRs')\n",
    "# define the p-value\n",
    "print(1 - ss.hypergeom(M, n, N).cdf(k))\n",
    "\n",
    "# repeat for the random TCRs\n",
    "M  = a_trb.shape[0] + len(seqs[~seqs.isin(a_trb.obs.index)].unique())\n",
    "n = len(pd.Series(trbs_rand).unique())\n",
    "N = len(seqs.unique())\n",
    "k = len(set(trbs_rand) & set(seqs))\n",
    "# define the distribution\n",
    "fig, ax = plt.subplots(figsize=[4, 2]); ax.grid(False)\n",
    "xl = np.arange(0, 26, 1)\n",
    "yl = ss.hypergeom(M, n, N).pmf(xl)\n",
    "ax.plot(xl, yl*100, color='grey', linestyle='--')\n",
    "ax.axvline(k, color='k', lw=2)\n",
    "ax.set(xlabel='# of Overlapping Unique TCRs', ylabel='Probability', title='Random TCRs')\n",
    "# define the p-value\n",
    "print(1 - ss.hypergeom(M, n, N).cdf(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c452c1-6b7a-4baf-a547-0ff1bf79ad69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# look at the percentage reported\n",
    "fig, ax = plt.subplots(figsize=[8, 4]); ax.grid(False)\n",
    "counts = seqs.value_counts()\n",
    "ax.bar(counts.index[:25], counts[:25], edgecolor='dodgerblue', color='skyblue', lw=1.5)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.set(xlabel='Generated TCRs (Top 25)', ylabel='# of TCRs Generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96ad81b-2a57-47b0-b431-d2f607c3d8d7",
   "metadata": {},
   "source": [
    "### Retrain AgFlow Without CASSPDIEAFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca1352-6967-40f2-8e6e-8fd8cafe42e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "torch.manual_seed(0); np.random.seed(0)\n",
    "flow = RealNVP(nets, nett, masks, prior)\n",
    "optimizer = torch.optim.Adam([p for p in flow.parameters() if p.requires_grad==True], lr=1e-5)\n",
    "# derive the mapping dataset\n",
    "trbs = df.loc[df['AG'] == 'YLQPRTFLL', 'TRB']\n",
    "trbs = trbs[trbs.isin(a_trb.obs.index)]\n",
    "# EXCLUSION\n",
    "trbs = trbs[trbs != 'CASSPDIEAFF']\n",
    "\n",
    "X = a_trb[trbs].X.astype(np.float32).copy()\n",
    "# track the loss values\n",
    "losses = []\n",
    "for t in range(10001):\n",
    "    # derive the loss\n",
    "    loss = -flow.log_prob(torch.from_numpy(X).to('cuda')).mean()\n",
    "    # optimize accordingly\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    if t % 1000 == 0:\n",
    "        print('iter %s:' % t, 'loss = %.3f' % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18c8bf3-b97f-4b76-84e6-9adf72af63a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the loss curve\n",
    "fig, ax = plt.subplots(); ax.grid(False)\n",
    "ax.plot(losses, color='dodgerblue')\n",
    "ax.set(xlabel='Epochs', ylabel='Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069144e7-339f-4696-997b-492603db7514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample from the dataset and confirm similarity with previous\n",
    "torch.manual_seed(0); np.random.seed(0)\n",
    "x = flow.sample(1000).clone().cpu().detach().numpy()\n",
    "umap = neigh.predict(x[:, 0, :])\n",
    "\n",
    "# derive the predicted\n",
    "fig, ax = plt.subplots(); ax.grid(False)\n",
    "ax.scatter(a_trb.obsm['X_umap'][:, 0], a_trb.obsm['X_umap'][:, 1], s=0.0001, color='lightgray')\n",
    "z = ss.gaussian_kde(umap.T)(umap.T); idxs = np.argsort(z)\n",
    "ax.scatter(umap[idxs, 0], umap[idxs, 1], c=z[idxs], alpha=0.5, s=4, cmap='Blues')\n",
    "ax.set_title(r'$\\hat{x} = g(z)$')\n",
    "\n",
    "# derive the ground truth\n",
    "# compare with the known\n",
    "fig, ax = plt.subplots(); ax.grid(False)\n",
    "ax.scatter(a_trb.obsm['X_umap'][:, 0], a_trb.obsm['X_umap'][:, 1], s=0.0001, color='lightgray')\n",
    "z = ss.gaussian_kde(a_trb[trbs].obsm['X_umap'].T)(a_trb[trbs].obsm['X_umap'].T); idxs = np.argsort(z)\n",
    "ax.scatter(a_trb[trbs].obsm['X_umap'][idxs, 0], a_trb[trbs].obsm['X_umap'][idxs, 1], c=z[idxs], alpha=0.5, s=4, cmap='Blues')\n",
    "ax.set_title(r'$x$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eef156-62a2-476d-8cd2-686f736af190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# attempt to generate some peptides\n",
    "seqs = []\n",
    "for idx in tqdm(range(x.shape[0]), total=x.shape[0]):\n",
    "    seqs.append(engine(model, torch.from_numpy(x[idx, 0, :].astype(np.float32)).to('cuda')))\n",
    "seqs = pd.Series(seqs)\n",
    "# look at the percentage reported\n",
    "fig, ax = plt.subplots(figsize=[8, 4]); ax.grid(False)\n",
    "counts = seqs.value_counts()\n",
    "ax.bar(counts.index[:25], counts[:25], edgecolor='dodgerblue', color='skyblue', lw=1.5)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.set(xlabel='Generated TCRs (Top 25)', ylabel='# of TCRs Generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb746d1-2e0e-4d65-a5de-eaeaa713923e",
   "metadata": {},
   "source": [
    "### Repeat Exercise Robustly via Multiple Random Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f7bf6-b231-42b6-b992-21d86dd8a26d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# derive the mapping dataset\n",
    "trbs = df.loc[df['AG'] == 'YLQPRTFLL', 'TRB']\n",
    "trbs = trbs[trbs.isin(a_trb.obs.index)]\n",
    "trbs = trbs[trbs != 'CASSPDIEAFF']\n",
    "len(trbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a6cbfd-5821-4b07-bf8e-f683bad983c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve the stats\n",
    "df_stat = pd.DataFrame(columns=['seed1','seed2','size','pos_per_mil'])\n",
    "for size in list(range(100, 700+100, 100))+[797]:\n",
    "    for seed in range(5):\n",
    "        print('-', end='')\n",
    "        # define optimizer\n",
    "        torch.manual_seed(seed); np.random.seed(seed)\n",
    "        flow = RealNVP(nets, nett, masks, prior)\n",
    "        optimizer = torch.optim.Adam([p for p in flow.parameters() if p.requires_grad==True], lr=1e-5)\n",
    "        # derive the mapping dataset\n",
    "        trbs = df.loc[df['AG'] == 'YLQPRTFLL', 'TRB']\n",
    "        trbs = trbs[trbs.isin(a_trb.obs.index)]\n",
    "        trbs = trbs[trbs != 'CASSPDIEAFF']\n",
    "\n",
    "        trbs = np.random.choice(trbs, size=size, replace=False)\n",
    "\n",
    "        X = a_trb[trbs].X.astype(np.float32).copy()\n",
    "        # track the loss values\n",
    "        losses = []\n",
    "        for t in range(10001):\n",
    "            # derive the loss\n",
    "            loss = -flow.log_prob(torch.from_numpy(X).to('cuda')).mean()\n",
    "            # optimize accordingly\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        print('.', end='')\n",
    "                                \n",
    "        # sample from the dataset\n",
    "        for seed2 in range(5):\n",
    "            torch.manual_seed(seed2); np.random.seed(seed2)\n",
    "            x = flow.sample(1000).clone().cpu().detach().numpy()\n",
    "            # attempt to generate some peptides\n",
    "            seqs = []\n",
    "            for idx in range(x.shape[0]):\n",
    "                seqs.append(engine(model, torch.from_numpy(x[idx, 0, :].astype(np.float32)).to('cuda')))\n",
    "            seqs = pd.Series(seqs)\n",
    "            # look at the percentage reported\n",
    "            df_stat.loc[df_stat.shape[0]] = seed, seed2, size, sum(seqs == 'CASSPDIEAFF')\n",
    "        print('>', end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b8ee0e-d75d-4318-ae84-b9432f812eb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the results\n",
    "df_stat.to_csv('../outs/250420_AgFlow_YLQdetections.positive.csv')\n",
    "df_stat = pd.read_csv('../outs/250420_AgFlow_YLQdetections.positive.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a9ed8-3e77-4605-81f2-7da51a1a2000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# examine the distribution limiting to seed to seed\n",
    "mask = (df_stat['seed1'] == df_stat['seed2']) & (df_stat['size'] != 797)\n",
    "fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "sns.barplot(x='size', y='pos_per_mil', data=df_stat[mask], ax=ax,\n",
    "            saturation=1, errcolor='dodgerblue', errwidth=1.5, capsize=0.3,\n",
    "            edgecolor='dodgerblue', linewidth=1.5, color='skyblue')\n",
    "mean = df_stat.loc[(df_stat['seed1'] == df_stat['seed2']) & (df_stat['size'] == 797)]['pos_per_mil'].mean()\n",
    "ci95 = df_stat.loc[(df_stat['seed1'] == df_stat['seed2']) & (df_stat['size'] == 797)]['pos_per_mil'].std() / np.sqrt(5) * 1.96\n",
    "ax.axhline(mean, color='grey', lw=2, linestyle='--', zorder=0,\n",
    "           label='Mean Recovery When\\nTrained on All (N=797)\\nNon-CASSPDIEAFF TCRs')\n",
    "ax.set_xlim(-1, 7)\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.fill([xmin, xmax, xmax, xmin, xmin],\n",
    "        [mean-ci95, mean-ci95, mean+ci95, mean+ci95, mean-ci95],\n",
    "        color='k', lw=2, linestyle='--', alpha=0.25, zorder=0, \n",
    "        label='95% Confidence Interval When\\nTrained on All (N=797)\\nNon-CASSPDIEAFF TCRs')\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.set(xlabel='# of Non-CASSPDIEAFF\\nYLQ-specific TCRs for Training',\n",
    "       ylabel='# of Embeddings\\nMapped to CASSPDIEAFF')\n",
    "ax.set_xlim(-0.75, 6.75)\n",
    "ax.legend(bbox_to_anchor=(1, .5), bbox_transform=ax.transAxes, loc='center left', frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b8f675-4dee-4f14-96c9-177bb82311e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve the stats for random background\n",
    "df_stat = pd.DataFrame(columns=['seed1','seed2','size','pos_per_mil'])\n",
    "for size in list(range(100, 700+100, 100))+[797]:\n",
    "    for seed in range(5):\n",
    "        print('-', end='')\n",
    "        # define optimizer\n",
    "        torch.manual_seed(seed); np.random.seed(seed)\n",
    "        flow = RealNVP(nets, nett, masks, prior)\n",
    "        optimizer = torch.optim.Adam([p for p in flow.parameters() if p.requires_grad==True], lr=1e-5)\n",
    "        # derive the mapping dataset\n",
    "        trbs = np.random.choice(a_trb.obs.index, size=size, replace=False)\n",
    "\n",
    "        X = a_trb[trbs].X.astype(np.float32).copy()\n",
    "        # track the loss values\n",
    "        losses = []\n",
    "        for t in range(10001):\n",
    "            # derive the loss\n",
    "            loss = -flow.log_prob(torch.from_numpy(X).to('cuda')).mean()\n",
    "            # optimize accordingly\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        print('.', end='')\n",
    "                                \n",
    "        # sample from the dataset\n",
    "        for seed2 in range(5):\n",
    "            torch.manual_seed(seed2); np.random.seed(seed2)\n",
    "            x = flow.sample(1000).clone().cpu().detach().numpy()\n",
    "            # attempt to generate some peptides\n",
    "            seqs = []\n",
    "            for idx in range(x.shape[0]):\n",
    "                seqs.append(engine(model, torch.from_numpy(x[idx, 0, :].astype(np.float32)).to('cuda')))\n",
    "            seqs = pd.Series(seqs)\n",
    "            # look at the percentage reported\n",
    "            df_stat.loc[df_stat.shape[0]] = seed, seed2, size, sum(seqs == 'CASSPDIEAFF')\n",
    "        print('>', end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7da81e-4156-4f16-856d-158695ca7cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the results\n",
    "df_stat.to_csv('../outs/250420_AgFlow_YLQdetections.random.csv')\n",
    "df_stat = pd.read_csv('../outs/250420_AgFlow_YLQdetections.random.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9afc2b-d144-430d-ba82-1c7babdecf24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# examine the distribution limiting to seed to seed\n",
    "mask = (df_stat['seed1'] == df_stat['seed2']) & (df_stat['size'] != 797)\n",
    "fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "sns.barplot(x='size', y='pos_per_mil', data=df_stat[mask], ax=ax,\n",
    "            saturation=1, errcolor='grey', errwidth=1.5, capsize=0.3,\n",
    "            edgecolor='grey', linewidth=1.5, color='lightgray')\n",
    "mean = df_stat.loc[(df_stat['seed1'] == df_stat['seed2']) & (df_stat['size'] == 797)]['pos_per_mil'].mean()\n",
    "ci95 = df_stat.loc[(df_stat['seed1'] == df_stat['seed2']) & (df_stat['size'] == 797)]['pos_per_mil'].std() / np.sqrt(5) * 1.96\n",
    "ax.axhline(mean, color='grey', lw=2, linestyle='--', zorder=0,\n",
    "           label='Mean Recovery When\\nTrained on All (N=797)\\nRandom TCRs')\n",
    "ax.set_xlim(-1, 7)\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.fill([xmin, xmax, xmax, xmin, xmin],\n",
    "        [mean-ci95, mean-ci95, mean+ci95, mean+ci95, mean-ci95],\n",
    "        color='k', lw=2, linestyle='--', alpha=0.25, zorder=0, \n",
    "        label='95% Confidence Interval When\\nTrained on All (N=797)\\nRandom TCRs')\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.set(xlabel='# of Random TCRs for Training',\n",
    "       ylabel='# of Embeddings\\nMapped to CASSPDIEAFF')\n",
    "ax.set_xlim(-0.75, 6.75)\n",
    "ax.legend(bbox_to_anchor=(1, .5), bbox_transform=ax.transAxes, loc='center left', frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc7c597-bdbe-4bb7-b006-e8486a9952ef",
   "metadata": {},
   "source": [
    "### Train AgFlow on Multiple Epitopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bf7137-ce15-48b5-84c5-19f95aacbc30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in the data\n",
    "df = pd.read_csv('../outs/df.int.clean.csv', index_col=0)\n",
    "# walk through each pack (epitope)\n",
    "packs = []\n",
    "epitopes = ['YLQPRTFLL','NLVPMVATV','TPRVTGGGAM','GILGFVFTL','GLCTLVAML','YVLDHLIVV',\n",
    "            'ELAGIGILTV','EAAGIGILTV','SLLMWITQC','KLGGALQAK','AVFDRKSDAK','RAKFKQLL',\n",
    "            'IVTDFSVIK','LLWNGPMAV','SPRWYFYYL','TTDPSFLGRY','RLRAEAQVK','LLLDRLNQL',\n",
    "            'LTDEMIAQY','CINGVCWTV','KTFPPTEPK','QYIKWPWYI','VMTTVLATL','DATYQRTRALVR','NQKLIANQF','FLCMKALLL']\n",
    "for epitope in tqdm(epitopes):\n",
    "    # define optimizer\n",
    "    torch.manual_seed(0); np.random.seed(0)\n",
    "    flow = RealNVP(nets, nett, masks, prior)\n",
    "    optimizer = torch.optim.Adam([p for p in flow.parameters() if p.requires_grad==True], lr=1e-5)\n",
    "    # derive the mapping dataset\n",
    "    trbs = df.loc[df['AG'] == epitope, 'TRB']\n",
    "    trbs = trbs[trbs.isin(a_trb.obs.index)]\n",
    "    X = a_trb[trbs].X.astype(np.float32).copy()\n",
    "    # track the loss values\n",
    "    losses = []\n",
    "    for t in range(10001):\n",
    "        # derive the loss\n",
    "        loss = -flow.log_prob(torch.from_numpy(X).to('cuda')).mean()\n",
    "        # optimize accordingly\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    # sample from the dataset\n",
    "    torch.manual_seed(0); np.random.seed(0)\n",
    "    x = flow.sample(1000).clone().cpu().detach().numpy()\n",
    "    umap = neigh.predict(x[:, 0, :])\n",
    "    \n",
    "    # look at the range of pvalues\n",
    "    pvals = []\n",
    "    for idx in range(a_trb.shape[1]):\n",
    "        p = ss.ks_2samp(x[:, 0, idx], a_trb[trbs].X[:, idx], alternative='two-sided')[1]\n",
    "        pvals.append(p)\n",
    "    pvals_truth = pvals\n",
    "    # compare against a random subset\n",
    "    np.random.seed(0)\n",
    "    trbs_rand = np.random.choice(a_trb.obs.index, size=len(trbs) * 3, replace=True)\n",
    "    pvals = []\n",
    "    for idx in range(a_trb.shape[1]):\n",
    "        p = ss.ks_2samp(x[:, 0, idx], a_trb[trbs_rand].X[:, idx], alternative='two-sided')[1]\n",
    "        pvals.append(p)\n",
    "    pvals_rand = pvals\n",
    "    pack1 = np.mean(-np.log10(pvals_truth)), np.mean(-np.log10(pvals_rand)), ss.mannwhitneyu(pvals_truth, pvals_rand)[1]\n",
    "\n",
    "    # attempt to generate some peptides\n",
    "    seqs = []\n",
    "    for idx in range(x.shape[0]):\n",
    "        seqs.append(engine(model, torch.from_numpy(x[idx, 0, :].astype(np.float32)).to('cuda')))\n",
    "    seqs = pd.Series(seqs)\n",
    "\n",
    "    # hypergeometric where you have M animals, n are dogs, then you choose a random N from the M animals how many are dogs\n",
    "    # in our scenario this is where we have the entire TCRbeta-ome supplemented with generated samples\n",
    "    M  = a_trb.shape[0] + len(seqs[~seqs.isin(a_trb.obs.index)].unique())\n",
    "    n = len(trbs.unique())\n",
    "    N = len(seqs.unique())\n",
    "    k = len(set(trbs) & set(seqs))\n",
    "    # define the p-value\n",
    "    p1 = 1 - ss.hypergeom(M, n, N).cdf(k)\n",
    "\n",
    "    # repeat for the random TCRs\n",
    "    M  = a_trb.shape[0] + len(seqs[~seqs.isin(a_trb.obs.index)].unique())\n",
    "    n = len(pd.Series(trbs_rand).unique())\n",
    "    N = len(seqs.unique())\n",
    "    k = len(set(trbs_rand) & set(seqs))\n",
    "    # define the p-value\n",
    "    p2 = 1 - ss.hypergeom(M, n, N).cdf(k)\n",
    "    pack2 = p1, p2\n",
    "    pack = pd.Series(pack1 + pack2, index=['mean_nlog10p_vstrue','mean_nlog10p_vsrand','pval_nlog10p','pval_vstruth','pval_vsrand'])\n",
    "    pack.name = epitope\n",
    "    print(epitope)\n",
    "    packs.append(pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860bf8f6-0f98-467d-9744-72a266965da6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save all results for retrieval later on\n",
    "pack = pd.concat(packs, axis=1)\n",
    "pack.to_csv('../outs/NVP.stats.csv')\n",
    "# derive the melted version\n",
    "pack_melt = pack.loc[['pval_vstruth','pval_vsrand']].T.reset_index().melt(id_vars='index')\n",
    "pack_melt['value_melt'] = -np.log10(pack_melt['value']+1e-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a9251a-b83e-480f-a853-8f0ca8c59606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize across epitopes\n",
    "fig, ax = plt.subplots(figsize=[16, 4]); ax.grid(False)\n",
    "sns.barplot(x='index', y='value_melt', hue='variable', data=pack_melt, saturation=1,\n",
    "            palette=['skyblue','lightgray'], edgecolor='dodgerblue', linewidth=1.5)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.legend(bbox_to_anchor=(1, .5), bbox_transform=ax.transAxes, frameon=False, title=None, loc='center left')\n",
    "ax.set(ylabel='-log$_{10}$(p-value) for the\\nProbability of Overlap')\n",
    "ax.get_children()[-2].get_children()[0].get_children()[1].get_children()[0].get_children()[1]\\\n",
    ".get_children()[0].get_children()[0].set_edgecolor('grey')\n",
    "ax.get_children()[-2].get_children()[0].get_children()[1].get_children()[0].get_children()[0]\\\n",
    ".get_children()[1].get_children()[0].set_text('Model vs.\\nTruth')\n",
    "ax.get_children()[-2].get_children()[0].get_children()[1].get_children()[0].get_children()[1]\\\n",
    ".get_children()[1].get_children()[0].set_text('Model vs.\\nRandom')\n",
    "for rect in ax.get_children()[52:78]:\n",
    "    rect.set_edgecolor('grey')\n",
    "ax.set_xlim(-1, len(epitopes))\n",
    "ax.set(xlabel=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc5410-ea70-4ba1-b262-3e7d37e12555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the p-values\n",
    "fig, ax = plt.subplots(figsize=[8, 4]); ax.grid(False)\n",
    "ax.bar(pack.columns, -np.log10(pack.loc['pval_nlog10p']),\n",
    "       lw=1.5, edgecolor='dodgerblue', color='skyblue')\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.set(ylabel='-log$_{10}$(p-value) for KS \\nModel vs. Random\\nand Model vs. Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6f686d-accb-487a-a9fa-ff5bcebaa996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# derive the ground truth for GILGFVFTL\n",
    "np.random.seed(0)\n",
    "trbs = np.random.choice(a_trb.obs.index, size=3000, replace=False)\n",
    "# compare with the known\n",
    "fig, ax = plt.subplots(); ax.grid(False)\n",
    "ax.scatter(a_trb.obsm['X_umap'][:, 0], a_trb.obsm['X_umap'][:, 1], s=0.0001, color='lightgray')\n",
    "z = ss.gaussian_kde(a_trb[trbs].obsm['X_umap'].T)(a_trb[trbs].obsm['X_umap'].T); idxs = np.argsort(z)\n",
    "ax.scatter(a_trb[trbs].obsm['X_umap'][idxs, 0], a_trb[trbs].obsm['X_umap'][idxs, 1], c=z[idxs], alpha=0.5, s=4, cmap='Blues')\n",
    "ax.set_title(r'$x$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e567fab4-e6ce-4240-8019-fd7a46fe284a",
   "metadata": {},
   "source": [
    "### Compare AgFlow Generated TCRs with Experimentally Validated TCRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da12414-daac-4634-a062-7d526d8d18b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in the data\n",
    "df = pd.read_csv('../outs/df.int.clean.csv', index_col=0)\n",
    "\n",
    "# 256 stands for the quantization I believe, the mask is a checkerboard type\n",
    "nets = lambda: nn.Sequential(nn.Linear(32, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 32), nn.Tanh()).to('cuda')\n",
    "nett = lambda: nn.Sequential(nn.Linear(32, 256), nn.LeakyReLU(), nn.Linear(256, 256), nn.LeakyReLU(), nn.Linear(256, 32)).to('cuda')\n",
    "masks = torch.from_numpy(np.array([[0, 1]*16, [1, 0]*16] * 4).astype(np.float32)).to('cuda')\n",
    "prior = distributions.MultivariateNormal(torch.zeros(32).to('cuda'), torch.eye(32).to('cuda'))\n",
    "\n",
    "# define optimizer\n",
    "torch.manual_seed(0); np.random.seed(0)\n",
    "flow = RealNVP(nets, nett, masks, prior)\n",
    "optimizer = torch.optim.Adam([p for p in flow.parameters() if p.requires_grad==True], lr=1e-5)\n",
    "# derive the mapping dataset\n",
    "trbs = df.loc[df['AG'] == 'YLQPRTFLL', 'TRB']\n",
    "trbs = trbs[trbs.isin(a_trb.obs.index)]\n",
    "X = a_trb[trbs].X.astype(np.float32).copy()\n",
    "# track the loss values\n",
    "losses = []\n",
    "for t in range(10001):\n",
    "    # derive the loss\n",
    "    loss = -flow.log_prob(torch.from_numpy(X).to('cuda')).mean()\n",
    "    # optimize accordingly\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    if t % 1000 == 0:\n",
    "        print('iter %s:' % t, 'loss = %.3f' % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8a3637-882c-445e-8b96-2b39796a6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have alr settled on a stretch length\n",
    "targ_len = 48\n",
    "\n",
    "# define a function to embed an amino acid with direct, bcp, blosum, and length\n",
    "def embed_aa(aa):\n",
    "    embed = [x for x in map_direct[aa]]\n",
    "    embed += map_bcp[aa]\n",
    "    embed += map_blosum[aa]\n",
    "    embed += [0]\n",
    "    return embed\n",
    "\n",
    "# define a function to interpolate the protein\n",
    "def stretch_pep(embedding, targ_len=targ_len):\n",
    "    # get the current protein length\n",
    "    orig_len, n_features = embedding.shape\n",
    "    # derive the original and current lengths\n",
    "    x = np.linspace(0, 1, targ_len)\n",
    "    xp = np.linspace(0, 1, orig_len)\n",
    "    # loop through each of the columns\n",
    "    tensor = torch.Tensor(embedding.T.reshape(1, n_features, orig_len))\n",
    "    res = torch.nn.functional.interpolate(tensor, size=(targ_len), mode='linear', align_corners=False)[0]\n",
    "    # add an the extra length information\n",
    "    res[-1, :] = orig_len\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c73e43-6977-4b63-a2a2-8a23ef3166de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in experimentally validated data\n",
    "df = pd.read_csv('../external_data/EXTERNAL_TONTCRVDB/01_05_2025_TCRvdb.csv', index_col=0)\n",
    "df_ylq = df.loc[df['epitope_aa'] == 'YLQPRTFLL']\n",
    "# read in the training data from public databases\n",
    "df_clean = pd.read_csv('../outs/df.int.clean.csv', index_col=0)\n",
    "df_clean_ylq = df_clean.loc[df_clean['AG'] == 'YLQPRTFLL'].copy()\n",
    "\n",
    "# process the TRBs\n",
    "trb_to_embed = {}\n",
    "trbs = pd.Series(df_ylq['cdr3_beta_aa'].unique())\n",
    "for sequence in tqdm(trbs):\n",
    "    # retrieve the embedding\n",
    "    embedding = np.array([embed for embed in map(embed_aa, list(sequence))])\n",
    "    # stretch the embedding\n",
    "    embedding = stretch_pep(embedding, targ_len=targ_len)\n",
    "    # save the embedding\n",
    "    trb_to_embed[sequence] = embedding\n",
    "\n",
    "# embed all of our unique TRBs\n",
    "X_trbs = torch.stack([x.to(torch.float32) for x in trbs.map(trb_to_embed)])\n",
    "# create a latent space for the trbs\n",
    "loader = DataLoader(dataset=TensorDataset(X_trbs), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# get the encoded dimensions\n",
    "torch.manual_seed(0); np.random.seed(0)\n",
    "# move through each subset in the complete loader\n",
    "z_dims_per_batch = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(loader):\n",
    "        data = data[0].to(device)\n",
    "        enc_out = model.encode(data)\n",
    "        # sampling centers around the mean so we just use mu\n",
    "        z_dims_per_batch.append(enc_out[0].clone().detach().cpu().numpy())\n",
    "z_dims = np.vstack(z_dims_per_batch)\n",
    "del data, enc_out, z_dims_per_batch\n",
    "\n",
    "# get prediction from tarpon ylq to the values\n",
    "trbs = df_clean_ylq['TRB'].copy()\n",
    "trbs = trbs[trbs.isin(a_trb.obs.index)]\n",
    "# get the mapping\n",
    "tarpon_ylq = pd.DataFrame(z_dims, index=trbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b019810a-1c3d-4b53-b2b3-8cf61194ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "# split the data\n",
    "mapping = df_ylq.groupby('cdr3_beta_aa').mean(numeric_only=True)['log2FoldChange']\n",
    "y = mapping.dropna().copy()\n",
    "X = tarpon_ylq.loc[y.index]\n",
    "skf = ShuffleSplit(n_splits=10, random_state=0, test_size=1/4)\n",
    "rmses, prhos, srhos, coefs, preds, pred_tests, true_tests = [], [], [], [], [], [], []\n",
    "for idxs_train, idxs_test in skf.split(X, y):\n",
    "    # instantiate the linear regression model\n",
    "    clf = LinearRegression()\n",
    "    clf = clf.fit(X.iloc[idxs_train], y.iloc[idxs_train])\n",
    "    # derive the probabilities\n",
    "    pred = clf.predict(X.iloc[idxs_test])\n",
    "    true = y.iloc[idxs_test]\n",
    "    pred_tests.append(pd.Series(pred, index=X.index[idxs_test]))\n",
    "    true_tests.append(pd.Series(true, index=X.index[idxs_test]))\n",
    "    rmses.append(np.sqrt(np.mean((pred - true) ** 2)))\n",
    "    prhos.append(ss.pearsonr(pred, true)[0])\n",
    "    srhos.append(ss.spearmanr(pred, true)[0])\n",
    "    preds.append(clf.predict(aylq.X))\n",
    "    coefs.append(clf.coef_)\n",
    "# evaluate models\n",
    "np.random.seed(0)\n",
    "fig, axs = plt.subplots(1, 3, figsize=[5, 3])\n",
    "for ax in axs: ax.grid(False)\n",
    "sns.boxplot(rmses, ax=axs[0], saturation=1, linewidth=1.5, linecolor='dodgerblue', color='skyblue')\n",
    "sns.stripplot(rmses, ax=axs[0], jitter=0.3, alpha=0.5, linewidth=1.5, edgecolor='dodgerblue', color='skyblue')\n",
    "axs[0].set_ylabel('RMSE')\n",
    "sns.boxplot(prhos, ax=axs[1], saturation=1, linewidth=1.5, linecolor='dodgerblue', color='skyblue')\n",
    "sns.stripplot(prhos, ax=axs[1], jitter=0.3, alpha=0.5, linewidth=1.5, edgecolor='dodgerblue', color='skyblue')\n",
    "axs[1].set_ylabel('Pearson Rho')\n",
    "sns.boxplot(srhos, ax=axs[2], saturation=1, linewidth=1.5, linecolor='dodgerblue', color='skyblue')\n",
    "sns.stripplot(srhos, ax=axs[2], jitter=0.3, alpha=0.5, linewidth=1.5, edgecolor='dodgerblue', color='skyblue')\n",
    "axs[2].set_ylabel('Spearman Rho')\n",
    "fig.tight_layout()\n",
    "print(np.mean(prhos), np.std(prhos) / np.sqrt(10) * 1.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef8b5d9-07ab-4a6a-8b77-158019e0b0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the TCRs that are well validated by Ton's dataset\n",
    "fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "pred, true = pd.concat(pred_tests, axis=0), pd.concat(true_tests, axis=0)\n",
    "sns.kdeplot(x=pred, y=true, bw_adjust=0.8, thresh=0.2, alpha=0.8, levels=8, fill=True, cmap='Blues')\n",
    "ax.scatter(pred, true, alpha=0.25, s=1, color='skyblue')\n",
    "ax.set(xlabel='Predicted YLQ Specificity', ylabel='Experimental YLQ Specificity')\n",
    "ax.set_xlim(-1.4, 2.7); ax.set_ylim(-1.7, 4.5)\n",
    "# determine rhos\n",
    "rhos = [ss.pearsonr(pred, true)[0] for pred, true in zip(pred_tests, true_tests)]\n",
    "np.mean(rhos), np.std(rhos) / np.sqrt(10) * 1.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94919a8f-ef2b-4e21-91af-1bd28d27c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from the dataset 1M times\n",
    "torch.manual_seed(0); np.random.seed(0)\n",
    "xs = []\n",
    "for _ in tqdm(range(100)):\n",
    "    xs.append(flow.sample(10000).clone().cpu().detach().numpy())\n",
    "x = np.vstack(xs)\n",
    "# attempt to generate some peptides\n",
    "seqs = []\n",
    "for idx in tqdm(range(x.shape[0]), total=x.shape[0]):\n",
    "    seqs.append(engine(model, torch.from_numpy(x[idx, 0, :].astype(np.float32)).to('cuda')))\n",
    "seqs = pd.Series(seqs)\n",
    "seqs_unique = pd.Series(seqs.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bda7d55-7453-4324-bd42-6fef79492f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "df_int = pd.read_csv('../outs/df.int.clean.csv', index_col=0)\n",
    "# derive the mapping dataset\n",
    "trbs = df_int.loc[df_int['AG'] == 'YLQPRTFLL', 'TRB']\n",
    "trbs = trbs[trbs.isin(a_trb.obs.index)]\n",
    "trbs_training = trbs.unique()\n",
    "trbs_generated = seqs_unique\n",
    "trbs_tested = tarpon_ylq.index\n",
    "# get the list of all TRBs\n",
    "trbs = trbs_tested.union(trbs_training).union(trbs_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c479f0-1eaa-4319-bfcc-719264a0e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process all YLQ TRBs\n",
    "trb_to_embed = {}\n",
    "trbs = pd.Series(trbs)\n",
    "for sequence in tqdm(trbs):\n",
    "    # retrieve the embedding\n",
    "    embedding = np.array([embed for embed in map(embed_aa, list(sequence))])\n",
    "    # stretch the embedding\n",
    "    embedding = stretch_pep(embedding, targ_len=targ_len)\n",
    "    # save the embedding\n",
    "    trb_to_embed[sequence] = embedding\n",
    "\n",
    "# embed all of our unique TRBs\n",
    "X_trbs = torch.stack([x.to(torch.float32) for x in trbs.map(trb_to_embed)])\n",
    "loader = DataLoader(dataset=TensorDataset(X_trbs), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# get the encoded dimensions\n",
    "torch.manual_seed(0); np.random.seed(0)\n",
    "# move through each subset in the complete loader\n",
    "z_dims_per_batch = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(loader):\n",
    "        data = data[0].to(device)\n",
    "        enc_out = model.encode(data)\n",
    "        # sampling centers around the mean so we just use mu\n",
    "        z_dims_per_batch.append(enc_out[0].clone().detach().cpu().numpy())\n",
    "z_dims = np.vstack(z_dims_per_batch)\n",
    "del data, enc_out, z_dims_per_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f1d09-d9e3-4cfa-aafb-e27dfaba8801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anndata import AnnData\n",
    "# assemble the anndata object and compute UMAP\n",
    "aylq = AnnData(z_dims)\n",
    "aylq.obs.index = trbs\n",
    "sc.pp.neighbors(aylq, use_rep='X', random_state=0)\n",
    "sc.tl.umap(aylq, random_state=0)\n",
    "# derive where the TCR came from\n",
    "aylq.obs['was_generated'] = 1 * aylq.obs.index.isin(trbs_generated)\n",
    "aylq.obs['was_experimentalDB'] = 1 * aylq.obs.index.isin(trbs_tested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a96ac40-d835-4c32-b1b8-0a266e452e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot on the logFC from the experimental data\n",
    "aylq.obs['enrich_generation'] = np.log10(aylq.obs.index.map(seqs.value_counts()))\n",
    "aylq.obs['enrich_experimental'] = -aylq.obs.index.map(mapping)\n",
    "mask = ~aylq.obs['enrich_experimental'].isna()\n",
    "ax = sc.pl.umap(aylq[~mask], show=False, s=0.5)\n",
    "sc.pl.umap(aylq[mask], color=['enrich_experimental'], cmap='Blues', ax=ax,\n",
    "           s=40, vmin=-1, vmax=5, edgecolor='k', linewidth=0.5, alpha=0.9)\n",
    "# write the data\n",
    "aylq.write('250605_sampled_1M_YLQ_TCRs.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dbbdf5-6921-4d9d-bfcc-ffc5e550f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot on the generated number of YLQs\n",
    "ax = sc.pl.umap(aylq, show=False)\n",
    "xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
    "# randomly sample the data\n",
    "mask = aylq.obs['was_generated'] == 1\n",
    "np.random.seed(0)\n",
    "counts = seqs.value_counts().loc[aylq.obs.index[mask]]\n",
    "percs = counts / counts.sum()\n",
    "idxs = np.random.choice(aylq.obs.index[mask], size=10000, replace=True, p=percs)\n",
    "sns.kdeplot(x=aylq[idxs].obsm['X_umap'][:, 0], y=aylq[idxs].obsm['X_umap'][:, 1],\n",
    "            cmap='Blues', thresh=0.2, fill=True, alpha=0.8, bw_adjust=0.8)\n",
    "ax.set_xlim(*xlim); ax.set_ylim(*ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc7eef0-e92d-4e5e-a2de-164a0b20946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive the average and 95% confidence interval of experimental by prediction\n",
    "means, ci95s = [], []\n",
    "xs = np.arange(0, 4+1, 1)\n",
    "for idx, vmax in enumerate(xs[1:]):\n",
    "    vmin = xs[idx]\n",
    "    mask = (aylq.obs['enrich_generation'] >= vmin)\n",
    "    if vmax != 10:\n",
    "        mask = mask & (aylq.obs['enrich_generation'] < vmax)\n",
    "    means.append(aylq.obs.loc[mask, 'enrich_experimental'].mean())\n",
    "    ci95s.append(aylq.obs.loc[mask, 'enrich_experimental'].std() / np.sqrt(sum(mask)) * 1.96)\n",
    "# compare the percentages\n",
    "fig, ax = plt.subplots(figsize=[3, 4])\n",
    "ax.grid(False)\n",
    "ax.scatter(xs[1:], means, color='dodgerblue')\n",
    "for idx, x in enumerate(xs[1:]):\n",
    "    mean = means[idx]\n",
    "    ci95 = ci95s[idx]\n",
    "    ax.plot([x]*2, [mean-ci95, mean+ci95], color='dodgerblue')\n",
    "    ax.plot([x-0.05, x+0.05], [mean-ci95]*2, color='dodgerblue')\n",
    "    ax.plot([x-0.05, x+0.05], [mean+ci95]*2, color='dodgerblue')\n",
    "ax.set(xlabel='log10(# of CDR3s)\\nfrom YLQ AgFlow Model', ylabel='Experimental YLQ Specificity\\nfrom Messemaker et al. 2025')\n",
    "ax.set_xticks(np.arange(1, 4+1, 1))\n",
    "ax.set_xticklabels([f'[10$^{vmax-1}$, 10$^{vmax}$)' if vmax != 4 else '[10$^3$, 10$^4$)' for vmax in np.arange(1, 4+1, 1)])\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ss.pearsonr(xs[1:], means)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu39",
   "language": "python",
   "name": "gpu39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
