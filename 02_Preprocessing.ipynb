{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b268d-f574-4e2b-b9bf-3e7c17118025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "sc.settings.set_figure_params(dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45809013-bf2a-4934-944f-1166d0211b2d",
   "metadata": {},
   "source": [
    "### Clean TCRs and Ags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9daebb-a78b-4c94-b1c7-10684c014879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "# read in the data\n",
    "df = pd.read_csv('../outs/df.int.clean.csv', index_col=0)\n",
    "# define antigen and TRA/TRB repertoire\n",
    "ags = pd.Series(df['AG'].unique()); print(len(ags))\n",
    "tras = pd.Series(df['TRA'].unique()); print(len(tras))\n",
    "trbs = pd.Series(df['TRB'].unique()); print(len(trbs))\n",
    "\n",
    "# load the pickled data\n",
    "with open('../external_data/results.tcr.pkl', 'rb') as f:\n",
    "    results_tcr = pkl.load(f)\n",
    "with open('../external_data/results.ag.pkl', 'rb') as f:\n",
    "    results_ag = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77638c7b-4eeb-4366-9a6b-1ea27ae115f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# track the antigens to load in and expand the list\n",
    "ags_ = []\n",
    "# define the columns for each to load in as a potential antigen\n",
    "cols = ['Predicted MANA sequence','WT sequence','MANA tested in culture']\n",
    "for col in cols:\n",
    "    ags_.extend(results_ag['CAUSHI_NATURE2021_NSCLC'][col].dropna().tolist())\n",
    "# repeat for the other studies\n",
    "cols = ['mut peptide','ref peptide']\n",
    "for col in cols:\n",
    "    ags_.extend(results_ag['MILLER_SCITRANSMED2024_PANCAN'][col].dropna().tolist())\n",
    "cols = ['Mutant Neoantigen Sequence', 'WT Neoantigen Sequence', 'MHC-I Mutant Epitope (Best Prediction)', 'MHC-I WT Epitope']\n",
    "for col in cols:\n",
    "    ags_.extend(results_ag['ROJAS_NATURE2023_PDAC'][col].dropna().tolist())\n",
    "ags = pd.Series(list(set(ags.tolist()+ags_))).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28c8967-de3d-41e4-bffa-3936c0770186",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# add on resources\n",
    "tras_, trbs_ = [], []\n",
    "for key in tqdm(results_tcr):\n",
    "    # try to add on tras\n",
    "    if 'TRA' in results_tcr[key].columns.tolist():\n",
    "        mask = results_tcr[key]['TRA'].astype(str).isin(['Cnan','nan'])\n",
    "        results_tcr[key]['TRA'][mask] = np.nan\n",
    "        tras_.extend(results_tcr[key]['TRA'].dropna().tolist())\n",
    "    # try to add on trbs\n",
    "    if 'TRB' in results_tcr[key].columns.tolist():\n",
    "        mask = results_tcr[key]['TRB'].astype(str).isin(['Cnan','nan'])\n",
    "        results_tcr[key]['TRB'][mask] = np.nan\n",
    "        trbs_.extend(results_tcr[key]['TRB'].dropna().tolist())\n",
    "    # try to add on paired\n",
    "    if ('TRA' in results_tcr[key].columns.tolist()) & ('TRB' in results_tcr[key].columns.tolist()):\n",
    "        tmp = results_tcr[key][['TRA','TRB']].reset_index().iloc[:, 1:].dropna()\n",
    "        tmp['DB'] = key\n",
    "        tmp['TcellType'] = results_tcr[key]['TcellType'].reset_index().iloc[:, 1:].loc[tmp.index]\n",
    "        df = pd.concat([df, tmp], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ecc1b-7e33-44d9-b8db-d6442fa9f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the paired TCRs and the counts\n",
    "paired_tcrs = df[['TRA','TRB']].value_counts().reset_index()\n",
    "# demonstrate the significant extension of tras and trbs\n",
    "tras = pd.Series(list(set(tras.tolist()+tras_))).unique()\n",
    "trbs = pd.Series(list(set(trbs.tolist()+trbs_))).unique()\n",
    "# save those values\n",
    "with open('../external_data/db.ags.pkl', 'wb') as f: pkl.dump(ags, f)\n",
    "with open('../external_data/db.tras.pkl', 'wb') as f: pkl.dump(tras, f)\n",
    "with open('../external_data/db.trbs.pkl', 'wb') as f: pkl.dump(trbs, f)\n",
    "with open('../external_data/db.paired_tcrs.pkl', 'wb') as f: pkl.dump(paired_tcrs, f)\n",
    "df.to_csv('../outs/df.int.clean.extended.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecfc1c5-6c7f-4292-9e18-1034d74c56dd",
   "metadata": {},
   "source": [
    "### Embed Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2154ff37-903e-48b2-a0d9-d706c473b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import blosum as bl\n",
    "# perform encoding by direct, BCP, BLOSUM\n",
    "vocab = ['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','Y']\n",
    "# direct encoding\n",
    "map_direct = {x:[1 * (x == y) for y in vocab] for x in vocab}\n",
    "# bcp encoding\n",
    "aa_hydrophobicity = {\n",
    "    'A': 1.8,  # Alanine\n",
    "    'R': -4.5,  # Arginine\n",
    "    'N': -3.5,  # Asparagine\n",
    "    'D': -3.5,  # Aspartic Acid\n",
    "    'C': 2.5,  # Cysteine\n",
    "    'E': -3.5,  # Glutamic Acid\n",
    "    'Q': -3.5,  # Glutamine\n",
    "    'G': -0.4,  # Glycine\n",
    "    'H': -3.2,  # Histidine\n",
    "    'I': 4.5,  # Isoleucine\n",
    "    'L': 3.8,  # Leucine\n",
    "    'K': -3.9,  # Lysine\n",
    "    'M': 1.9,  # Methionine\n",
    "    'F': 2.8,  # Phenylalanine\n",
    "    'P': -1.6,  # Proline\n",
    "    'S': -0.8,  # Serine\n",
    "    'T': -0.7,  # Threonine\n",
    "    'W': -0.9,  # Tryptophan\n",
    "    'Y': -1.3,  # Tyrosine\n",
    "    'V': 4.2,  # Valine\n",
    "}\n",
    "# https://www.imgt.org/IMGTeducation/Aide-memoire/_UK/aminoacids/IMGTclasses.html\n",
    "aa_volume = {\n",
    "    'A': 88.6,   # Alanine\n",
    "    'R': 173.4,  # Arginine\n",
    "    'N': 114.1,  # Asparagine\n",
    "    'D': 111.1,  # Aspartic Acid\n",
    "    'C': 108.5,  # Cysteine\n",
    "    'E': 138.4,  # Glutamic Acid\n",
    "    'Q': 143.8,  # Glutamine\n",
    "    'G': 60.1,   # Glycine\n",
    "    'H': 153.2,  # Histidine\n",
    "    'I': 166.7,  # Isoleucine\n",
    "    'L': 166.7,  # Leucine\n",
    "    'K': 168.6,  # Lysine\n",
    "    'M': 162.9,  # Methionine\n",
    "    'F': 189.9,  # Phenylalanine\n",
    "    'P': 112.7,  # Proline\n",
    "    'S': 89.0,   # Serine\n",
    "    'T': 116.1,  # Threonine\n",
    "    'W': 227.8,  # Tryptophan\n",
    "    'Y': 193.6,  # Tyrosine\n",
    "    'V': 140.0,  # Valine\n",
    "}\n",
    "# 1 = donor and acceptor, 0.5 = only donor or acceptor\n",
    "aa_hbond = {\n",
    "    'A': 0,    # Alanine\n",
    "    'R': 0.5,  # Arginine\n",
    "    'N': 1,    # Asparagine\n",
    "    'D': 0.5,  # Aspartic Acid\n",
    "    'C': 0,    # Cysteine\n",
    "    'E': 0.5,  # Glutamic Acid\n",
    "    'Q': 1,    # Glutamine\n",
    "    'G': 0,    # Glycine\n",
    "    'H': 1,    # Histidine\n",
    "    'I': 0,    # Isoleucine\n",
    "    'L': 0,    # Leucine\n",
    "    'K': 0.5,  # Lysine\n",
    "    'M': 0,    # Methionine\n",
    "    'F': 0,    # Phenylalanine\n",
    "    'P': 0,    # Proline\n",
    "    'S': 1,    # Serine\n",
    "    'T': 1,    # Threonine\n",
    "    'W': 0.5,  # Tryptophan\n",
    "    'Y': 1,    # Tyrosine\n",
    "    'V': 0,    # Valine\n",
    "}\n",
    "has_sulfur = ['C','M']\n",
    "is_aromatic = ['F','Y','W']\n",
    "is_aliphatic = ['A','G','I','L','P','V']\n",
    "is_basic = ['R','H','K']\n",
    "is_acidic = ['D','E']\n",
    "has_amide = ['N','Q']\n",
    "vocab_bcp = ['hydrophobicity','volume','hbond','has_sulfur','is_aromatic',\n",
    "             'is_aliphatic','is_basic','is_acidic','has_amide']\n",
    "# > normalize the data for both volume and charge\n",
    "vmin, vmax = min(list(aa_volume.values())), max(list(aa_volume.values()))\n",
    "aa_volume = {k:(v-vmin)/(vmax-vmin) for k,v in aa_volume.items()}\n",
    "vmax = max(abs(np.array(list(aa_hydrophobicity.values()))))\n",
    "aa_hydrophobicity = {k:v/vmax for k,v in aa_hydrophobicity.items()}\n",
    "# > define a method to return the embedding for a given amino acid in BCP space\n",
    "def bcp_translation(aa):\n",
    "    embedding = []\n",
    "    embedding.append(aa_hydrophobicity[aa])\n",
    "    embedding.append(aa_volume[aa])\n",
    "    embedding.append(aa_hbond[aa])\n",
    "    embedding.append(1 * (aa in has_sulfur))\n",
    "    embedding.append(1 * (aa in is_aromatic))\n",
    "    embedding.append(1 * (aa in is_aliphatic))\n",
    "    embedding.append(1 * (aa in is_basic))\n",
    "    embedding.append(1 * (aa in is_acidic))\n",
    "    embedding.append(1 * (aa in has_amide))\n",
    "    return embedding\n",
    "map_bcp = {x:bcp_translation(x) for x in vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da12fd50-8c59-4d41-90df-ad4bbceb1d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide how to normalize the blosum matrix\n",
    "xs = range(1, 10+1)\n",
    "ys = [np.mean(abs(pd.DataFrame({x:[bl.BLOSUM(62)[x][y]/idx for y in vocab] for x in vocab}).values.flatten()) < 1) for idx in xs]\n",
    "# create the elbow like plot\n",
    "fig, ax = plt.subplots(); ax.grid(False)\n",
    "ax.scatter(xs, np.array(ys)*100, edgecolor='dodgerblue', color='skyblue', lw=1.5)\n",
    "ax.set(xlabel='Denominator', ylabel='% of |values| < 1')\n",
    "# blosum encoding with five as shown above\n",
    "map_blosum = {x:[bl.BLOSUM(62)[x][y] / 5 for y in vocab] for x in vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67978398-d53b-4bec-9b69-f4466fdfb2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to embed an amino acid with direct, bcp, blosum, and length\n",
    "def embed_aa(aa):\n",
    "    embed = [x for x in map_direct[aa]]\n",
    "    embed += map_bcp[aa]\n",
    "    embed += map_blosum[aa]\n",
    "    embed += [0]\n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ad761-f2db-4e2a-bd7a-6288be1c4a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "# define the number of samples per case\n",
    "n_samples = 100\n",
    "# define the number of lengths to test\n",
    "targ_lens = range(5, 101, 5); mses = []\n",
    "for targ_len in targ_lens:\n",
    "    # set seed for reproducibility\n",
    "    np.random.seed(0)\n",
    "    # track the MSEs\n",
    "    mse = 0\n",
    "    for sequence in np.random.choice(tras, size=n_samples, replace=False):\n",
    "        # retrieve the original length\n",
    "        orig_len = len(sequence)\n",
    "        # retrieve the embedding\n",
    "        embedding = np.array([embed for embed in map(embed_aa, list(sequence))])\n",
    "        tensor = torch.Tensor(embedding.T.reshape(1, 50, orig_len))\n",
    "        res = torch.nn.functional.interpolate(tensor, size=(targ_len), mode='linear', align_corners=False)[0].T\n",
    "        res_p = torch.nn.functional.interpolate(res.T.view((1, 50, targ_len)), size=(orig_len), mode='linear', align_corners=False)[0].T\n",
    "        mse += (res_p - embedding).pow(2).sum()\n",
    "    mses.append(torch.sqrt(mse / n_samples))\n",
    "# create the elbow like plot\n",
    "fig, ax = plt.subplots(); ax.grid(False)\n",
    "ax.scatter(targ_lens, mses, edgecolor='dodgerblue', color='skyblue', lw=1.5)\n",
    "ax.set(xlabel='TRA stretch length', ylabel='Average reconstruction loss')\n",
    "tra_mses = [x for x in mses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a6713-eec9-4bc5-923b-de6a93ea8ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the number of lengths to test\n",
    "targ_lens = range(5, 101, 5); mses = []\n",
    "for targ_len in targ_lens:\n",
    "    # set seed for reproducibility\n",
    "    np.random.seed(0)\n",
    "    # track the MSEs\n",
    "    mse = 0\n",
    "    for sequence in np.random.choice(trbs, size=n_samples, replace=False):\n",
    "        # retrieve the original length\n",
    "        orig_len = len(sequence)\n",
    "        # retrieve the embedding\n",
    "        embedding = np.array([embed for embed in map(embed_aa, list(sequence))])\n",
    "        tensor = torch.Tensor(embedding.T.reshape(1, 50, orig_len))\n",
    "        res = torch.nn.functional.interpolate(tensor, size=(targ_len), mode='linear', align_corners=False)[0].T\n",
    "        res_p = torch.nn.functional.interpolate(res.T.view((1, 50, targ_len)), size=(orig_len), mode='linear', align_corners=False)[0].T\n",
    "        mse += (res_p - embedding).pow(2).sum()\n",
    "    mses.append(torch.sqrt(mse / n_samples))\n",
    "# create the elbow like plot\n",
    "fig, ax = plt.subplots(); ax.grid(False)\n",
    "ax.scatter(targ_lens, mses, edgecolor='dodgerblue', color='skyblue', lw=1.5)\n",
    "ax.set(xlabel='TRB stretch length', ylabel='Average reconstruction loss')\n",
    "trb_mses = [x for x in mses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86effa5-bc19-4f9e-9625-08c1fa2343e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the number of lengths to test\n",
    "targ_lens = range(5, 101, 5); mses = []\n",
    "for targ_len in targ_lens:\n",
    "    # set seed for reproducibility\n",
    "    np.random.seed(0)\n",
    "    # track the MSEs\n",
    "    mse = 0\n",
    "    for sequence in np.random.choice(ags, size=n_samples, replace=False):\n",
    "        # retrieve the original length\n",
    "        orig_len = len(sequence)\n",
    "        # retrieve the embedding\n",
    "        embedding = np.array([embed for embed in map(embed_aa, list(sequence))])\n",
    "        tensor = torch.Tensor(embedding.T.reshape(1, 50, orig_len))\n",
    "        res = torch.nn.functional.interpolate(tensor, size=(targ_len), mode='linear', align_corners=False)[0].T\n",
    "        res_p = torch.nn.functional.interpolate(res.T.view((1, 50, targ_len)), size=(orig_len), mode='linear', align_corners=False)[0].T\n",
    "        mse += (res_p - embedding).pow(2).sum()\n",
    "    mses.append(torch.sqrt(mse / n_samples))\n",
    "# create the elbow like plot\n",
    "fig, ax = plt.subplots(); ax.grid(False)\n",
    "ax.scatter(targ_lens, mses, edgecolor='dodgerblue', color='skyblue', lw=1.5)\n",
    "ax.set(xlabel='AG stretch length', ylabel='Average reconstruction loss')\n",
    "ag_mses = [x for x in mses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ed9784-5beb-490d-bffe-e08dc1c9e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the elbow like plot\n",
    "fig, ax = plt.subplots(); ax.grid(False)\n",
    "ax.scatter(targ_lens, [ag_mses[idx]+tra_mses[idx]+trb_mses[idx] for idx in range(len(targ_lens))],\n",
    "           edgecolor='dodgerblue', color='skyblue', lw=1.5)\n",
    "ax.set(xlabel='Stretch length (ALL)', ylabel='Average reconstruction loss (SUM)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82701ded-cd63-490e-aa22-9378bc11898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we therefore settle on a stretch length\n",
    "targ_len = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa3d600-8909-4424-8ba0-6af0b050a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# define a function to interpolate the protein\n",
    "def stretch_pep(embedding, targ_len=targ_len):\n",
    "    # get the current protein length\n",
    "    orig_len, n_features = embedding.shape\n",
    "    # derive the original and current lengths\n",
    "    x = np.linspace(0, 1, targ_len)\n",
    "    xp = np.linspace(0, 1, orig_len)\n",
    "    # loop through each of the columns\n",
    "    tensor = torch.Tensor(embedding.T.reshape(1, n_features, orig_len))\n",
    "    res = torch.nn.functional.interpolate(tensor, size=(targ_len), mode='linear', align_corners=False)[0]\n",
    "    # add an the extra length information\n",
    "    res[-1, :] = orig_len\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c433f9b0-a823-40ca-a412-d88c98421d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# process the TRAs\n",
    "tra_to_embed = {}\n",
    "for sequence in tqdm(tras):\n",
    "    # retrieve the embedding\n",
    "    embedding = np.array([embed for embed in map(embed_aa, list(sequence))])\n",
    "    # stretch the embedding\n",
    "    embedding = stretch_pep(embedding, targ_len=targ_len)\n",
    "    # save the embedding\n",
    "    tra_to_embed[sequence] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0203444-5142-492f-8a5e-ac73fd520908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the TRBs\n",
    "trb_to_embed = {}\n",
    "for sequence in tqdm(trbs):\n",
    "    # retrieve the embedding\n",
    "    embedding = np.array([embed for embed in map(embed_aa, list(sequence))])\n",
    "    # stretch the embedding\n",
    "    embedding = stretch_pep(embedding, targ_len=targ_len)\n",
    "    # save the embedding\n",
    "    trb_to_embed[sequence] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab4c044-e504-45bc-98fd-0156da42dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the AGs\n",
    "ag_to_embed = {}\n",
    "for sequence in tqdm(ags):\n",
    "    # retrieve the embedding\n",
    "    embedding = np.array([embed for embed in map(embed_aa, list(sequence))])\n",
    "    # stretch the embedding\n",
    "    embedding = stretch_pep(embedding, targ_len=targ_len)\n",
    "    # save the embedding\n",
    "    ag_to_embed[sequence] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76231a5-57d4-431d-8405-b3a6482fe873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "# save the embedding maps\n",
    "with open('../outs/map.tra_to_embed.extended.pkl', 'wb') as f: pkl.dump(tra_to_embed, f)\n",
    "with open('../outs/map.trb_to_embed.extended.pkl', 'wb') as f: pkl.dump(trb_to_embed, f)\n",
    "with open('../outs/map.ag_to_embed.extended.pkl', 'wb') as f: pkl.dump(ag_to_embed, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2984afc7-ed9b-475f-84de-c0ce0d76458e",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565729d9-ced0-4310-b000-40ce0864f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "# read in the aggregated values\n",
    "with open('../external_data/db.ags.pkl', 'rb') as f: ags = pkl.load(f)\n",
    "with open('../external_data/db.tras.pkl', 'rb') as f: tras = pkl.load(f)\n",
    "with open('../external_data/db.trbs.pkl', 'rb') as f: trbs = pkl.load(f)\n",
    "with open('../external_data/db.paired_tcrs.pkl', 'rb') as f: paired_tcrs = pkl.load(f)\n",
    "ags, tras, trbs = pd.Series(ags), pd.Series(tras), pd.Series(trbs)\n",
    "\n",
    "# move to uppercase\n",
    "ags = pd.Series(ags).str.upper()\n",
    "tras = pd.Series(tras).str.upper()\n",
    "trbs = pd.Series(trbs).str.upper()\n",
    "ags.shape[0], tras.shape[0], trbs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d778c71a-7005-493f-bf63-a249f135e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any sequences with an invalid letter\n",
    "for invalid in ['B','J','O','U','X','Z']:\n",
    "    ags = ags[~ags.str.contains(invalid)]\n",
    "    tras = tras[~tras.str.contains(invalid)]\n",
    "    trbs = trbs[~trbs.str.contains(invalid)]\n",
    "ags.shape[0], tras.shape[0], trbs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e09e487-52ea-4b4a-aaa3-b5c233799c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the histogram for TRA, TRB\n",
    "fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "ax.hist(tras.apply(len), edgecolor='dodgerblue', lw=1.5, color='skyblue', bins=20)\n",
    "ax.set(xlabel='TRA length', ylabel='Count')\n",
    "print(tras.apply(len).describe())\n",
    "fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "ax.hist(trbs.apply(len), edgecolor='dodgerblue', lw=1.5, color='skyblue', bins=20)\n",
    "ax.set(xlabel='TRB length', ylabel='Count')\n",
    "print(trbs.apply(len).describe())\n",
    "# examine the histogram for epitope, for peps\n",
    "fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "ax.hist(ags.apply(len), edgecolor='dodgerblue', lw=1.5, color='skyblue', bins=20)\n",
    "ax.set(xlabel='AG length', ylabel='Count')\n",
    "print(ags.apply(len).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a8bce-fa1d-441c-b121-385905b94a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the histogram for TRA, TRB\n",
    "fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "ax.hist(tras.apply(len)[(tras.apply(len) <= 24)&(tras.apply(len) >= 8)], edgecolor='dodgerblue', lw=1.5, color='skyblue', bins=15)\n",
    "ax.set(xlabel='TRA length', ylabel='Count')\n",
    "print(tras.apply(len).describe())\n",
    "fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "ax.hist(trbs.apply(len)[(trbs.apply(len) <= 24)&(trbs.apply(len) >= 8)], edgecolor='dodgerblue', lw=1.5, color='skyblue', bins=15)\n",
    "ax.set(xlabel='TRB length', ylabel='Count')\n",
    "print(trbs.apply(len).describe())\n",
    "# examine the histogram for epitope, for peps\n",
    "fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "ax.hist(ags.apply(len)[(ags.apply(len) <= 12)&(ags.apply(len) >= 8)], edgecolor='dodgerblue', lw=1.5, color='skyblue', bins=15)\n",
    "ax.set(xlabel='AG length', ylabel='Count')\n",
    "print(ags.apply(len).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898a221a-33ef-44ff-a920-a0298fefe2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset accordingly and save\n",
    "tras = tras[(tras.apply(len) <= 24)&(tras.apply(len) >= 8)]\n",
    "trbs = trbs[(trbs.apply(len) <= 24)&(trbs.apply(len) >= 8)]\n",
    "ags = ags[(ags.apply(len) <= 12)&(ags.apply(len) >= 8)]\n",
    "paired_tcrs = paired_tcrs[paired_tcrs['TRA'].isin(tras) & paired_tcrs['TRB'].isin(trbs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb38822-b888-4ee3-ab39-08d3f30df07a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check for any dups\n",
    "assert len([x for x in tras if x[:len(x)//2] == x[len(x)//2:]]) == 0\n",
    "assert len([x for x in trbs if x[:len(x)//2] == x[len(x)//2:]]) == 0\n",
    "assert len([x for x in ags if x[:len(x)//2] == x[len(x)//2:]]) == 0\n",
    "assert len([x for x in tras if x.count('CAS') > 2 | x.count('CSA') > 2]) == 0\n",
    "assert len([x for x in trbs if x.count('CAS') > 2 | x.count('CSA') > 2]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d43d541-66e8-4706-b4df-e989f577a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save those values\n",
    "with open('../external_data/db.ags.pkl', 'wb') as f: pkl.dump(ags, f)\n",
    "with open('../external_data/db.tras.pkl', 'wb') as f: pkl.dump(tras, f)\n",
    "with open('../external_data/db.trbs.pkl', 'wb') as f: pkl.dump(trbs, f)\n",
    "with open('../external_data/db.paired_tcrs.pkl', 'wb') as f: pkl.dump(paired_tcrs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef237f7-3abd-4fda-8069-0792efa1d85f",
   "metadata": {},
   "source": [
    "### Double Check Interpolation Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d723572e-050e-445f-aef3-6916e0f77a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "# define the number of samples per case\n",
    "n_samples = 100\n",
    "# define the number of lengths to test\n",
    "targ_lens = range(4, 101, 4)\n",
    "df_mse = pd.DataFrame(columns=['targ_len','rmse','seed'])\n",
    "for targ_len in targ_lens:\n",
    "    # set seed for reproducibility\n",
    "    for seed in range(5):\n",
    "        np.random.seed(seed)\n",
    "        # track the MSEs\n",
    "        mse = 0\n",
    "        for sequence in np.random.choice(tras, size=n_samples, replace=False):\n",
    "            # retrieve the original length\n",
    "            orig_len = len(sequence)\n",
    "            # retrieve the embedding\n",
    "            embedding = np.array([embed for embed in map(embed_aa, list(sequence))])\n",
    "            tensor = torch.Tensor(embedding.T.reshape(1, 50, orig_len))\n",
    "            res = torch.nn.functional.interpolate(tensor, size=(targ_len), mode='linear', align_corners=False)[0].T\n",
    "            res_p = torch.nn.functional.interpolate(res.T.view((1, 50, targ_len)), size=(orig_len), mode='linear', align_corners=False)[0].T\n",
    "            mse += (res_p - embedding).pow(2).sum()\n",
    "        rmse = torch.sqrt(mse / n_samples)\n",
    "        df_mse.loc[df_mse.shape[0]] = targ_len, rmse.item(), seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af055469-d5c1-4208-b8c2-b4184e153426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot in bar plot format\n",
    "fig, ax = plt.subplots(figsize=[8, 4]); ax.grid(False)\n",
    "sns.barplot(x='targ_len', y='rmse', data=df_mse, ci=95, errwidth=1.5, capsize=0.3, saturation=1,\n",
    "            errcolor='dodgerblue', edgecolor='dodgerblue', linewidth=1.5, color='skyblue')\n",
    "ax.set_xlim(-1, 25)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.set_xticklabels([int(float(x.get_text())) for x in ax.get_xticklabels()])\n",
    "ax.set(xlabel='Interpolated Length', ylabel='Root Mean Squared Error (RMSE)', title='CDR3α Amino Acid Identity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a298cad-4054-4a4e-8918-46dc03e42951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the number of lengths to test\n",
    "targ_lens = range(4, 101, 4)\n",
    "df_mse = pd.DataFrame(columns=['targ_len','rmse','seed'])\n",
    "for targ_len in targ_lens:\n",
    "    # set seed for reproducibility\n",
    "    for seed in range(5):\n",
    "        np.random.seed(seed)\n",
    "        # track the MSEs\n",
    "        mse = 0\n",
    "        for sequence in np.random.choice(trbs, size=n_samples, replace=False):\n",
    "            # retrieve the original length\n",
    "            orig_len = len(sequence)\n",
    "            # retrieve the embedding\n",
    "            embedding = np.array([embed for embed in map(embed_aa, list(sequence))])\n",
    "            tensor = torch.Tensor(embedding.T.reshape(1, 50, orig_len))\n",
    "            res = torch.nn.functional.interpolate(tensor, size=(targ_len), mode='linear', align_corners=False)[0].T\n",
    "            res_p = torch.nn.functional.interpolate(res.T.view((1, 50, targ_len)), size=(orig_len), mode='linear', align_corners=False)[0].T\n",
    "            mse += (res_p - embedding).pow(2).sum()\n",
    "        rmse = torch.sqrt(mse / n_samples)\n",
    "        df_mse.loc[df_mse.shape[0]] = targ_len, rmse.item(), seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38026084-1e70-4edc-8a61-73bb51eedab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot in bar plot format\n",
    "fig, ax = plt.subplots(figsize=[8, 4]); ax.grid(False)\n",
    "sns.barplot(x='targ_len', y='rmse', data=df_mse, ci=95, errwidth=1.5, capsize=0.3, saturation=1,\n",
    "            errcolor='dodgerblue', edgecolor='dodgerblue', linewidth=1.5, color='skyblue')\n",
    "ax.set_xlim(-1, 25)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.set_xticklabels([int(float(x.get_text())) for x in ax.get_xticklabels()])\n",
    "ax.set(xlabel='Interpolated Length', ylabel='Root Mean Squared Error (RMSE)', title='CDR3β Amino Acid Identity')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu39",
   "language": "python",
   "name": "gpu39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
