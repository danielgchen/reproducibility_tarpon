{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c9f34b-a022-463b-afb5-a2da05795983",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "sc.settings.set_figure_params(dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b970c80-10b7-4562-8ad9-5ca10438fcc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the minimum number of cells\n",
    "min_cells = 2\n",
    "# get the tag, keeping only pairs that have at least min_cells cells\n",
    "mask = results_tcr['ZHENG_SCIENCE2021_PANCAN']['TcellType'] == 'CD8'\n",
    "data = results_tcr['ZHENG_SCIENCE2021_PANCAN'].loc[mask, ['patient','cluster.name','TRB']].astype(str).copy()\n",
    "data['tag'] = data[['patient','cluster.name']].astype(str).agg(':'.join, axis=1)\n",
    "# filter the data more harshly because less assured of quality\n",
    "data['TRB'][~data['TRB'].isin(a_trb.obs.index)] = np.nan\n",
    "data = data.dropna(subset=['TRB'])\n",
    "counts = data['tag'].value_counts(); tags = counts.index[counts >= min_cells]\n",
    "# compile the Xs\n",
    "Xs = []\n",
    "for tag in tqdm(tags):\n",
    "    trbs = data.loc[data['tag'] == tag, 'TRB']\n",
    "    mask = trbs[trbs.isin(a_trb.obs.index)]\n",
    "    X_ = pd.Series(a_trb[mask].X.mean(0), name=tag)\n",
    "    Xs.append(X_)\n",
    "og_trb_zheng2021_X = pd.concat(Xs, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d380e81f-d4b1-427c-9e78-0847a710c357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# define a function to interrogate the data\n",
    "def interrogate_with_globals():\n",
    "    # create statistics tracking dataframe\n",
    "    df_stat = pd.DataFrame(columns=['auroc','auprc','f1_score','balacc'])\n",
    "    # create tracking variables for downstream visualization and statistics\n",
    "    probas, probas_bin, truths = [], [], []\n",
    "    fprs, tprs, pres, recs = [], [], [], []\n",
    "    # train utilizing random forest models in a stratified shuffled manner\n",
    "    skf = StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=1/4)\n",
    "    for idxs_train, idxs_test in skf.split(X1, y1):\n",
    "        # instantiate the random forest model\n",
    "        clf = LogisticRegression()\n",
    "        # fit the random forest model using Dataset #1\n",
    "        clf = clf.fit(X1.iloc[idxs_train], y1.iloc[idxs_train])\n",
    "\n",
    "        # predict on Dataset #2 correcting to all indices if requested\n",
    "        if pred_on_all:\n",
    "            idxs_test = range(X2.shape[0])\n",
    "        # derive the probabilities\n",
    "        proba = clf.predict_proba(X2.iloc[idxs_test])[:, clf.classes_ == 1]\n",
    "        probas.append(pd.Series(proba[:, 0], index=X2.index[idxs_test]))\n",
    "        # binarize into categorical predictions\n",
    "        proba_bin = 1 * (proba >= 0.50)\n",
    "        probas_bin.append(pd.Series(proba_bin[:, 0], index=X2.index[idxs_test]))\n",
    "        # retrieve the associated ground truth\n",
    "        truth = y2.iloc[idxs_test]\n",
    "        truths.append(truth.copy())\n",
    "\n",
    "        # compute subsequent AUROC and AUPRC related metrics\n",
    "        fpr, tpr, _ = roc_curve(truth, proba)\n",
    "        pre, rec, _ = precision_recall_curve(truth, proba)\n",
    "        fprs.append(fpr); tprs.append(tpr); pres.append(pre); recs.append(rec)\n",
    "        # save the relevant statistics\n",
    "        df_stat.loc[df_stat.shape[0]] = auc(fpr, tpr), auc(rec, pre), \\\n",
    "                                        f1_score(truth, proba_bin, average='binary'), \\\n",
    "                                        balanced_accuracy_score(truth, proba_bin)\n",
    "\n",
    "    # check the difference\n",
    "    for stat in df_stat.columns:\n",
    "        fig, ax = plt.subplots(figsize=[1, 4]); ax.grid(False)\n",
    "        sns.boxplot(y=df_stat[stat], linewidth=1.5, saturation=1, showfliers=False, linecolor='dodgerblue', color='skyblue')\n",
    "        sns.stripplot(y=df_stat[stat], linewidth=1.5, s=6, alpha=0.5, color='skyblue', edgecolor='dodgerblue')\n",
    "        ax.set_xlim(-0.75, 0.75); ax.set_ylabel(stat.upper())\n",
    "        print(stat.upper(), df_stat[stat].mean(), df_stat[stat].std() / np.sqrt(df_stat.shape[0])*1.96)\n",
    "\n",
    "    # plot the FPR, TPR\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for fpr, tpr in zip(fprs, tprs):\n",
    "        ax.plot(fpr, tpr, color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, fpr, tpr))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0, 1], color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "\n",
    "    # plot the precision recall\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for pre, rec in zip(pres, recs):\n",
    "        ax.plot(rec[::-1], pre[::-1], color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, rec[::-1], pre[::-1]))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0.5]*2, color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='Recall', ylabel='Precision')\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    # define the results\n",
    "    result = pd.DataFrame(columns=['Truth','PredProb'])\n",
    "    for proba, truth in zip(probas, truths):\n",
    "        result.loc[result.shape[0]] = '+', proba[truth == 1].mean()\n",
    "        result.loc[result.shape[0]] = '-', proba[truth == 0].mean()\n",
    "\n",
    "    # compare the average prediction probabilities\n",
    "    fig, ax = plt.subplots(figsize=[2, 4]); ax.grid(False)\n",
    "    sns.boxplot(x='Truth', y='PredProb', data=result, linewidth=1.5, saturation=1,\n",
    "                showfliers=False, linecolor='dodgerblue', color='skyblue',\n",
    "                order=['-', '+'], palette=['lightgray','skyblue'])\n",
    "    np.random.seed(0)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['dodgerblue'], order=['+'], alpha=0.6, s=6)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['grey'], order=['-'], alpha=0.6, s=6)\n",
    "    ax.set_xlim(-1, 2); ax.set_ylabel('Prediction Probability'); ax.set_xlabel('Ground Truth')\n",
    "    ax.get_children()[0].set_hatch('//')\n",
    "    ax.get_children()[0].set_edgecolor('grey')\n",
    "    for idx in range(1, 6):\n",
    "        ax.get_children()[idx].set_color('grey')\n",
    "\n",
    "    # report statistics\n",
    "    print('p-value for + vs. -:')\n",
    "    print(ss.mannwhitneyu(result.loc[result['Truth'] == '+', 'PredProb'], result.loc[result['Truth'] == '-', 'PredProb']))\n",
    "    print('average:')\n",
    "    print(df_stat.mean(0))\n",
    "    print('95% cis:')\n",
    "    print(df_stat.std(0) / np.sqrt(10) * 1.96)\n",
    "    return df_stat, probas, truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeabb3e-6785-4a37-a7f0-c66a8735397e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebe59d0-6c35-4a63-8bc1-8b47d91bbd01",
   "metadata": {},
   "source": [
    "## Fetal Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c5a576-a1d4-4487-906c-2fa8917455d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains(':TYPE_1_INNATE_T'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = False\n",
    "# perform predictions with all\n",
    "df_stat_fetal, _, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f80d990-270c-4c53-a917-2e78fb2c4069",
   "metadata": {},
   "source": [
    "## Fetal... --> COVID-19 and Adult Healthy Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95456ac2-cdc1-4fe8-932d-5730f6df9288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_su2022_X.copy()\n",
    "X2 = X2.loc[~X2.index.str.endswith('nan')]\n",
    "X2 = X2.loc[~X2.index.str.endswith('CD8_Naive_14')]\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('CD8_Cytotoxic_3'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_covid, probas_covid, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc8a947-0eea-45df-b88e-5d38ad9b73ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_covid, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Adult PT and HD CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d568c6-0458-43cd-a758-2c2255b406c9",
   "metadata": {},
   "source": [
    "## Fetal... --> Pan-Cancer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668dcb1f-515c-4dd4-8b45-9432e6771def",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_zheng2021_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('KIR'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_tumor, probas_tumor, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c5a79b-aa98-4b40-a953-314993b374c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_tumor, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Pan-Cancer CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a465f80e-21d8-42fd-bc39-739f2798c6e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a function to interrogate the data\n",
    "def interrogate_with_globals():\n",
    "    # create statistics tracking dataframe\n",
    "    df_stat = pd.DataFrame(columns=['auroc','auprc','f1_score','balacc'])\n",
    "    # create tracking variables for downstream visualization and statistics\n",
    "    probas, probas_bin, truths = [], [], []\n",
    "    fprs, tprs, pres, recs = [], [], [], []\n",
    "    # train utilizing random forest models in a stratified shuffled manner\n",
    "    skf = StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=1/4)\n",
    "    for idxs_train, idxs_test in skf.split(X1, y1):\n",
    "        # instantiate the random forest model\n",
    "        clf = RandomForestClassifier(random_state=0, n_estimators=100)\n",
    "        # fit the random forest model using Dataset #1\n",
    "        clf = clf.fit(X1.iloc[idxs_train], y1.iloc[idxs_train])\n",
    "\n",
    "        # predict on Dataset #2 correcting to all indices if requested\n",
    "        if pred_on_all:\n",
    "            idxs_test = range(X2.shape[0])\n",
    "        # derive the probabilities\n",
    "        proba = clf.predict_proba(X2.iloc[idxs_test])[:, clf.classes_ == 1]\n",
    "        probas.append(pd.Series(proba[:, 0], index=X2.index[idxs_test]))\n",
    "        # binarize into categorical predictions\n",
    "        proba_bin = 1 * (proba >= 0.50)\n",
    "        probas_bin.append(pd.Series(proba_bin[:, 0], index=X2.index[idxs_test]))\n",
    "        # retrieve the associated ground truth\n",
    "        truth = y2.iloc[idxs_test]\n",
    "        truths.append(truth.copy())\n",
    "\n",
    "        # compute subsequent AUROC and AUPRC related metrics\n",
    "        fpr, tpr, _ = roc_curve(truth, proba)\n",
    "        pre, rec, _ = precision_recall_curve(truth, proba)\n",
    "        fprs.append(fpr); tprs.append(tpr); pres.append(pre); recs.append(rec)\n",
    "        # save the relevant statistics\n",
    "        df_stat.loc[df_stat.shape[0]] = auc(fpr, tpr), auc(rec, pre), \\\n",
    "                                        f1_score(truth, proba_bin, average='binary'), \\\n",
    "                                        balanced_accuracy_score(truth, proba_bin)\n",
    "\n",
    "    # check the difference\n",
    "    for stat in df_stat.columns:\n",
    "        fig, ax = plt.subplots(figsize=[1, 4]); ax.grid(False)\n",
    "        sns.boxplot(y=df_stat[stat], linewidth=1.5, saturation=1, showfliers=False, linecolor='dodgerblue', color='skyblue')\n",
    "        sns.stripplot(y=df_stat[stat], linewidth=1.5, s=6, alpha=0.5, color='skyblue', edgecolor='dodgerblue')\n",
    "        ax.set_xlim(-0.75, 0.75); ax.set_ylabel(stat.upper())\n",
    "        print(stat.upper(), df_stat[stat].mean(), df_stat[stat].std() / np.sqrt(df_stat.shape[0])*1.96)\n",
    "\n",
    "    # plot the FPR, TPR\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for fpr, tpr in zip(fprs, tprs):\n",
    "        ax.plot(fpr, tpr, color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, fpr, tpr))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0, 1], color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "\n",
    "    # plot the precision recall\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for pre, rec in zip(pres, recs):\n",
    "        ax.plot(rec[::-1], pre[::-1], color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, rec[::-1], pre[::-1]))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0.5]*2, color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='Recall', ylabel='Precision')\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    # define the results\n",
    "    result = pd.DataFrame(columns=['Truth','PredProb'])\n",
    "    for proba, truth in zip(probas, truths):\n",
    "        result.loc[result.shape[0]] = '+', proba[truth == 1].mean()\n",
    "        result.loc[result.shape[0]] = '-', proba[truth == 0].mean()\n",
    "\n",
    "    # compare the average prediction probabilities\n",
    "    fig, ax = plt.subplots(figsize=[2, 4]); ax.grid(False)\n",
    "    sns.boxplot(x='Truth', y='PredProb', data=result, linewidth=1.5, saturation=1,\n",
    "                showfliers=False, linecolor='dodgerblue', color='skyblue',\n",
    "                order=['-', '+'], palette=['lightgray','skyblue'])\n",
    "    np.random.seed(0)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['dodgerblue'], order=['+'], alpha=0.6, s=6)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['grey'], order=['-'], alpha=0.6, s=6)\n",
    "    ax.set_xlim(-1, 2); ax.set_ylabel('Prediction Probability'); ax.set_xlabel('Ground Truth')\n",
    "    ax.get_children()[0].set_hatch('//')\n",
    "    ax.get_children()[0].set_edgecolor('grey')\n",
    "    for idx in range(1, 6):\n",
    "        ax.get_children()[idx].set_color('grey')\n",
    "\n",
    "    # report statistics\n",
    "    print('p-value for + vs. -:')\n",
    "    print(ss.mannwhitneyu(result.loc[result['Truth'] == '+', 'PredProb'], result.loc[result['Truth'] == '-', 'PredProb']))\n",
    "    print('average:')\n",
    "    print(df_stat.mean(0))\n",
    "    print('95% cis:')\n",
    "    print(df_stat.std(0) / np.sqrt(10) * 1.96)\n",
    "    return df_stat, probas, truths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ae44b0-fc62-444e-966b-5bee815bbdb7",
   "metadata": {},
   "source": [
    "## Fetal Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539141df-e9c1-45f8-8859-f8e4799a8c78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains(':TYPE_1_INNATE_T'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = False\n",
    "# perform predictions with all\n",
    "df_stat_fetal, _, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af13a4d4-a4c8-4ee6-b8a8-126f05224a72",
   "metadata": {},
   "source": [
    "## Fetal... --> COVID-19 and Adult Healthy Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b84146-5b62-4a39-b701-8a82f16d0bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_su2022_X.copy()\n",
    "X2 = X2.loc[~X2.index.str.endswith('nan')]\n",
    "X2 = X2.loc[~X2.index.str.endswith('CD8_Naive_14')]\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('CD8_Cytotoxic_3'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_covid, probas_covid, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e8c39f-9a57-4adc-b239-5c1497ae589e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_covid, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Adult PT and HD CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1753e79-6a0e-41fb-bcd0-11b6bb33c8cc",
   "metadata": {},
   "source": [
    "## Fetal... --> Pan-Cancer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343b41df-a51d-4f2c-9bd2-79a2fefc85b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_zheng2021_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('KIR'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_tumor, probas_tumor, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abea625e-7ff7-4fef-8f1c-f3cbdd2f082a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_tumor, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Pan-Cancer CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9e3eeb-c32c-4807-bbbc-a737e878d0f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a function to interrogate the data\n",
    "def interrogate_with_globals():\n",
    "    # create statistics tracking dataframe\n",
    "    df_stat = pd.DataFrame(columns=['auroc','auprc','f1_score','balacc'])\n",
    "    # create tracking variables for downstream visualization and statistics\n",
    "    probas, probas_bin, truths = [], [], []\n",
    "    fprs, tprs, pres, recs = [], [], [], []\n",
    "    # train utilizing random forest models in a stratified shuffled manner\n",
    "    skf = StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=1/4)\n",
    "    for idxs_train, idxs_test in skf.split(X1, y1):\n",
    "        # instantiate the random forest model\n",
    "        clf = RandomForestClassifier(random_state=0, n_estimators=200)\n",
    "        # fit the random forest model using Dataset #1\n",
    "        clf = clf.fit(X1.iloc[idxs_train], y1.iloc[idxs_train])\n",
    "\n",
    "        # predict on Dataset #2 correcting to all indices if requested\n",
    "        if pred_on_all:\n",
    "            idxs_test = range(X2.shape[0])\n",
    "        # derive the probabilities\n",
    "        proba = clf.predict_proba(X2.iloc[idxs_test])[:, clf.classes_ == 1]\n",
    "        probas.append(pd.Series(proba[:, 0], index=X2.index[idxs_test]))\n",
    "        # binarize into categorical predictions\n",
    "        proba_bin = 1 * (proba >= 0.50)\n",
    "        probas_bin.append(pd.Series(proba_bin[:, 0], index=X2.index[idxs_test]))\n",
    "        # retrieve the associated ground truth\n",
    "        truth = y2.iloc[idxs_test]\n",
    "        truths.append(truth.copy())\n",
    "\n",
    "        # compute subsequent AUROC and AUPRC related metrics\n",
    "        fpr, tpr, _ = roc_curve(truth, proba)\n",
    "        pre, rec, _ = precision_recall_curve(truth, proba)\n",
    "        fprs.append(fpr); tprs.append(tpr); pres.append(pre); recs.append(rec)\n",
    "        # save the relevant statistics\n",
    "        df_stat.loc[df_stat.shape[0]] = auc(fpr, tpr), auc(rec, pre), \\\n",
    "                                        f1_score(truth, proba_bin, average='binary'), \\\n",
    "                                        balanced_accuracy_score(truth, proba_bin)\n",
    "\n",
    "    # check the difference\n",
    "    for stat in df_stat.columns:\n",
    "        fig, ax = plt.subplots(figsize=[1, 4]); ax.grid(False)\n",
    "        sns.boxplot(y=df_stat[stat], linewidth=1.5, saturation=1, showfliers=False, linecolor='dodgerblue', color='skyblue')\n",
    "        sns.stripplot(y=df_stat[stat], linewidth=1.5, s=6, alpha=0.5, color='skyblue', edgecolor='dodgerblue')\n",
    "        ax.set_xlim(-0.75, 0.75); ax.set_ylabel(stat.upper())\n",
    "        print(stat.upper(), df_stat[stat].mean(), df_stat[stat].std() / np.sqrt(df_stat.shape[0])*1.96)\n",
    "\n",
    "    # plot the FPR, TPR\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for fpr, tpr in zip(fprs, tprs):\n",
    "        ax.plot(fpr, tpr, color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, fpr, tpr))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0, 1], color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "\n",
    "    # plot the precision recall\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for pre, rec in zip(pres, recs):\n",
    "        ax.plot(rec[::-1], pre[::-1], color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, rec[::-1], pre[::-1]))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0.5]*2, color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='Recall', ylabel='Precision')\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    # define the results\n",
    "    result = pd.DataFrame(columns=['Truth','PredProb'])\n",
    "    for proba, truth in zip(probas, truths):\n",
    "        result.loc[result.shape[0]] = '+', proba[truth == 1].mean()\n",
    "        result.loc[result.shape[0]] = '-', proba[truth == 0].mean()\n",
    "\n",
    "    # compare the average prediction probabilities\n",
    "    fig, ax = plt.subplots(figsize=[2, 4]); ax.grid(False)\n",
    "    sns.boxplot(x='Truth', y='PredProb', data=result, linewidth=1.5, saturation=1,\n",
    "                showfliers=False, linecolor='dodgerblue', color='skyblue',\n",
    "                order=['-', '+'], palette=['lightgray','skyblue'])\n",
    "    np.random.seed(0)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['dodgerblue'], order=['+'], alpha=0.6, s=6)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['grey'], order=['-'], alpha=0.6, s=6)\n",
    "    ax.set_xlim(-1, 2); ax.set_ylabel('Prediction Probability'); ax.set_xlabel('Ground Truth')\n",
    "    ax.get_children()[0].set_hatch('//')\n",
    "    ax.get_children()[0].set_edgecolor('grey')\n",
    "    for idx in range(1, 6):\n",
    "        ax.get_children()[idx].set_color('grey')\n",
    "\n",
    "    # report statistics\n",
    "    print('p-value for + vs. -:')\n",
    "    print(ss.mannwhitneyu(result.loc[result['Truth'] == '+', 'PredProb'], result.loc[result['Truth'] == '-', 'PredProb']))\n",
    "    print('average:')\n",
    "    print(df_stat.mean(0))\n",
    "    print('95% cis:')\n",
    "    print(df_stat.std(0) / np.sqrt(10) * 1.96)\n",
    "    return df_stat, probas, truths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a98628-7d3c-4f9d-ab6a-8051e10d9656",
   "metadata": {},
   "source": [
    "## Fetal Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c6d846-f6bd-476a-a46f-2ff17e175742",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains(':TYPE_1_INNATE_T'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = False\n",
    "# perform predictions with all\n",
    "df_stat_fetal, _, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4d609a-7bf4-419f-9856-b84f0664bea3",
   "metadata": {},
   "source": [
    "## Fetal... --> COVID-19 and Adult Healthy Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b489db8-ebef-4989-b5de-d6a5d1bd1045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_su2022_X.copy()\n",
    "X2 = X2.loc[~X2.index.str.endswith('nan')]\n",
    "X2 = X2.loc[~X2.index.str.endswith('CD8_Naive_14')]\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('CD8_Cytotoxic_3'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_covid, probas_covid, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e22363d-5944-4a70-a40f-16e7ca7675c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_covid, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Adult PT and HD CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d6d968-8fb2-468c-9614-54a2275278c8",
   "metadata": {},
   "source": [
    "## Fetal... --> Pan-Cancer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd63c17-ede0-4d1e-a334-89be5f793947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_zheng2021_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('KIR'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_tumor, probas_tumor, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a979ae04-3e31-4f0c-8250-d5c44d93b123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_tumor, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Pan-Cancer CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a690f67-1271-43c2-a3a9-56a6be1abd0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a function to interrogate the data\n",
    "def interrogate_with_globals():\n",
    "    # create statistics tracking dataframe\n",
    "    df_stat = pd.DataFrame(columns=['auroc','auprc','f1_score','balacc'])\n",
    "    # create tracking variables for downstream visualization and statistics\n",
    "    probas, probas_bin, truths = [], [], []\n",
    "    fprs, tprs, pres, recs = [], [], [], []\n",
    "    # train utilizing random forest models in a stratified shuffled manner\n",
    "    skf = StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=1/4)\n",
    "    for idxs_train, idxs_test in skf.split(X1, y1):\n",
    "        # instantiate the random forest model\n",
    "        clf = RandomForestClassifier(random_state=0, n_estimators=500)\n",
    "        # fit the random forest model using Dataset #1\n",
    "        clf = clf.fit(X1.iloc[idxs_train], y1.iloc[idxs_train])\n",
    "\n",
    "        # predict on Dataset #2 correcting to all indices if requested\n",
    "        if pred_on_all:\n",
    "            idxs_test = range(X2.shape[0])\n",
    "        # derive the probabilities\n",
    "        proba = clf.predict_proba(X2.iloc[idxs_test])[:, clf.classes_ == 1]\n",
    "        probas.append(pd.Series(proba[:, 0], index=X2.index[idxs_test]))\n",
    "        # binarize into categorical predictions\n",
    "        proba_bin = 1 * (proba >= 0.50)\n",
    "        probas_bin.append(pd.Series(proba_bin[:, 0], index=X2.index[idxs_test]))\n",
    "        # retrieve the associated ground truth\n",
    "        truth = y2.iloc[idxs_test]\n",
    "        truths.append(truth.copy())\n",
    "\n",
    "        # compute subsequent AUROC and AUPRC related metrics\n",
    "        fpr, tpr, _ = roc_curve(truth, proba)\n",
    "        pre, rec, _ = precision_recall_curve(truth, proba)\n",
    "        fprs.append(fpr); tprs.append(tpr); pres.append(pre); recs.append(rec)\n",
    "        # save the relevant statistics\n",
    "        df_stat.loc[df_stat.shape[0]] = auc(fpr, tpr), auc(rec, pre), \\\n",
    "                                        f1_score(truth, proba_bin, average='binary'), \\\n",
    "                                        balanced_accuracy_score(truth, proba_bin)\n",
    "\n",
    "    # check the difference\n",
    "    for stat in df_stat.columns:\n",
    "        fig, ax = plt.subplots(figsize=[1, 4]); ax.grid(False)\n",
    "        sns.boxplot(y=df_stat[stat], linewidth=1.5, saturation=1, showfliers=False, linecolor='dodgerblue', color='skyblue')\n",
    "        sns.stripplot(y=df_stat[stat], linewidth=1.5, s=6, alpha=0.5, color='skyblue', edgecolor='dodgerblue')\n",
    "        ax.set_xlim(-0.75, 0.75); ax.set_ylabel(stat.upper())\n",
    "        print(stat.upper(), df_stat[stat].mean(), df_stat[stat].std() / np.sqrt(df_stat.shape[0])*1.96)\n",
    "\n",
    "    # plot the FPR, TPR\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for fpr, tpr in zip(fprs, tprs):\n",
    "        ax.plot(fpr, tpr, color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, fpr, tpr))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0, 1], color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "\n",
    "    # plot the precision recall\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for pre, rec in zip(pres, recs):\n",
    "        ax.plot(rec[::-1], pre[::-1], color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, rec[::-1], pre[::-1]))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0.5]*2, color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='Recall', ylabel='Precision')\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    # define the results\n",
    "    result = pd.DataFrame(columns=['Truth','PredProb'])\n",
    "    for proba, truth in zip(probas, truths):\n",
    "        result.loc[result.shape[0]] = '+', proba[truth == 1].mean()\n",
    "        result.loc[result.shape[0]] = '-', proba[truth == 0].mean()\n",
    "\n",
    "    # compare the average prediction probabilities\n",
    "    fig, ax = plt.subplots(figsize=[2, 4]); ax.grid(False)\n",
    "    sns.boxplot(x='Truth', y='PredProb', data=result, linewidth=1.5, saturation=1,\n",
    "                showfliers=False, linecolor='dodgerblue', color='skyblue',\n",
    "                order=['-', '+'], palette=['lightgray','skyblue'])\n",
    "    np.random.seed(0)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['dodgerblue'], order=['+'], alpha=0.6, s=6)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['grey'], order=['-'], alpha=0.6, s=6)\n",
    "    ax.set_xlim(-1, 2); ax.set_ylabel('Prediction Probability'); ax.set_xlabel('Ground Truth')\n",
    "    ax.get_children()[0].set_hatch('//')\n",
    "    ax.get_children()[0].set_edgecolor('grey')\n",
    "    for idx in range(1, 6):\n",
    "        ax.get_children()[idx].set_color('grey')\n",
    "\n",
    "    # report statistics\n",
    "    print('p-value for + vs. -:')\n",
    "    print(ss.mannwhitneyu(result.loc[result['Truth'] == '+', 'PredProb'], result.loc[result['Truth'] == '-', 'PredProb']))\n",
    "    print('average:')\n",
    "    print(df_stat.mean(0))\n",
    "    print('95% cis:')\n",
    "    print(df_stat.std(0) / np.sqrt(10) * 1.96)\n",
    "    return df_stat, probas, truths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c0bf71-0364-4e8d-b939-3a3f45144d0a",
   "metadata": {},
   "source": [
    "## Fetal Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0806d7-54cd-4dfa-9bbf-20d5552dd1d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains(':TYPE_1_INNATE_T'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = False\n",
    "# perform predictions with all\n",
    "df_stat_fetal, _, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b6c27c-af3a-4803-891b-12caea9c6d74",
   "metadata": {},
   "source": [
    "## Fetal... --> COVID-19 and Adult Healthy Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811cb49-a7c2-428e-8d25-9143fcdbb612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_su2022_X.copy()\n",
    "X2 = X2.loc[~X2.index.str.endswith('nan')]\n",
    "X2 = X2.loc[~X2.index.str.endswith('CD8_Naive_14')]\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('CD8_Cytotoxic_3'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_covid, probas_covid, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2119843-278c-4ba8-9916-effa079cc71d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_covid, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Adult PT and HD CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33648d7e-4b71-4e9f-a168-ac916f993738",
   "metadata": {},
   "source": [
    "## Fetal... --> Pan-Cancer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f44f060-1b01-4d05-a3ec-a37563a7b3eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_zheng2021_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('KIR'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_tumor, probas_tumor, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fb09bd-2ff3-4cd8-878c-c66491229377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_tumor, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Pan-Cancer CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e56876-d266-4858-83c2-8e99bc1745bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fc2d277-b701-47f9-97f7-fb8f3a541f53",
   "metadata": {},
   "source": [
    "### Read in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccda3f77-30e6-412c-919d-28c314d468a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import auc, roc_curve, precision_recall_curve, f1_score, balanced_accuracy_score, accuracy_score\n",
    "import pickle as pkl\n",
    "# load the pickled data\n",
    "with open('../external_data/results.tcr.pkl', 'rb') as f:\n",
    "    results_tcr = pkl.load(f)\n",
    "\n",
    "# read in the values\n",
    "a_trb = sc.read_h5ad('../outs/adata.trb.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ada245-7909-4b2e-898a-5ebf80084af6",
   "metadata": {},
   "source": [
    "#### Fetal Donors (Suo and Dann et al. 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8408347f-9682-42c0-9b96-367a66e4b6e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# define the minimum number of cells\n",
    "min_cells = 4\n",
    "# get the tag, keeping only pairs that have at least min_cells cells\n",
    "clusters = ['CD8+T','TYPE_1_INNATE_T']\n",
    "mask = results_tcr['SUO_SCIENCE2022_FETAL']['celltype_annotation'].isin(clusters)\n",
    "data = results_tcr['SUO_SCIENCE2022_FETAL'].loc[mask, ['donor','celltype_annotation','TRB']].astype(str).copy()\n",
    "data['tag'] = data[['donor','celltype_annotation']].astype(str).agg(':'.join, axis=1)\n",
    "# filter the data more harshly because less assured of quality\n",
    "data['TRB'][~data['TRB'].isin(a_trb.obs.index)] = np.nan\n",
    "data = data.dropna(subset=['TRB'])\n",
    "counts = data['tag'].value_counts(); tags = counts.index[counts >= min_cells]\n",
    "# compile the Xs\n",
    "Xs = []\n",
    "for tag in tqdm(tags):\n",
    "    trbs = data.loc[data['tag'] == tag, 'TRB']\n",
    "    mask = trbs[trbs.isin(a_trb.obs.index)]\n",
    "    X_ = pd.Series(a_trb[mask].X.mean(0), name=tag)\n",
    "    Xs.append(X_)\n",
    "og_trb_suo2022_X = pd.concat(Xs, axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6905d2-89a3-4c5b-9ded-b983da3f30b2",
   "metadata": {},
   "source": [
    "#### Adults with COVID-19 and Healthy Donors (Su, Yuan, and Chen et al. 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cd9ed2-dee2-419f-a8f0-ac160a5c0bf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in the data\n",
    "adata = sc.read_h5ad('../../COVID_ISB_STORAGE/upto_v16_P_GE_int_gex_cd8_t_cells.has_abtcr_chain.h5ad')\n",
    "# derive annotations\n",
    "results_tcr['SU_CELL2022_COVID19']['phenotype_leiden'] = adata.obs[['phenotype','leiden']].agg('_'.join, axis=1)\n",
    "results_tcr['SU_CELL2022_COVID19'][['batch','subbatch','sample']] = \\\n",
    "results_tcr['SU_CELL2022_COVID19']['batch_info'].str.split(':', expand=True)\n",
    "\n",
    "# get the tag, keeping only pairs that have at least min_cells cells\n",
    "mask = ~results_tcr['SU_CELL2022_COVID19']['phenotype_leiden'].isna()\n",
    "data = results_tcr['SU_CELL2022_COVID19'][['sample','phenotype_leiden','TRB']].astype(str).copy()\n",
    "data['tag'] = data[['sample','phenotype_leiden']].astype(str).agg(':'.join, axis=1)\n",
    "# filter the data more harshly because less assured of quality\n",
    "data['TRB'][~data['TRB'].isin(a_trb.obs.index)] = np.nan\n",
    "data = data.dropna(subset=['TRB'])\n",
    "counts = data['tag'].value_counts(); tags = counts.index[counts >= min_cells]\n",
    "# compile the Xs\n",
    "Xs = []\n",
    "for tag in tqdm(tags):\n",
    "    trbs = data.loc[data['tag'] == tag, 'TRB']\n",
    "    mask = trbs[trbs.isin(a_trb.obs.index)]\n",
    "    X_ = pd.Series(a_trb[mask].X.mean(0), name=tag)\n",
    "    Xs.append(X_)\n",
    "og_trb_su2022_X = pd.concat(Xs, axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6a75ec-9f6f-4c94-b47f-495b696b9288",
   "metadata": {},
   "source": [
    "#### Pan-Cancer Types (Zheng, Qin, and Si et al. 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39301e0-e305-41e7-b5f2-3bc66f36bd46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the tag, keeping only pairs that have at least min_cells cells\n",
    "mask = results_tcr['ZHENG_SCIENCE2021_PANCAN']['TcellType'] == 'CD8'\n",
    "data = results_tcr['ZHENG_SCIENCE2021_PANCAN'].loc[mask, ['patient','cluster.name','TRB']].astype(str).copy()\n",
    "data['tag'] = data[['patient','cluster.name']].astype(str).agg(':'.join, axis=1)\n",
    "# filter the data more harshly because less assured of quality\n",
    "data['TRB'][~data['TRB'].isin(a_trb.obs.index)] = np.nan\n",
    "data = data.dropna(subset=['TRB'])\n",
    "counts = data['tag'].value_counts(); tags = counts.index[counts >= min_cells]\n",
    "# compile the Xs\n",
    "Xs = []\n",
    "for tag in tqdm(tags):\n",
    "    trbs = data.loc[data['tag'] == tag, 'TRB']\n",
    "    mask = trbs[trbs.isin(a_trb.obs.index)]\n",
    "    X_ = pd.Series(a_trb[mask].X.mean(0), name=tag)\n",
    "    Xs.append(X_)\n",
    "og_trb_zheng2021_X = pd.concat(Xs, axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb1b231-0109-4c1d-a387-e058e49ab73b",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada14839-71c7-4ed4-9945-a1c188f95b45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# define a function to interrogate the data\n",
    "def interrogate_with_globals():\n",
    "    # create statistics tracking dataframe\n",
    "    df_stat = pd.DataFrame(columns=['auroc','auprc'])\n",
    "    # create tracking variables for downstream visualization and statistics\n",
    "    probas, probas_bin, truths = [], [], []\n",
    "    fprs, tprs, pres, recs = [], [], [], []\n",
    "    # train utilizing random forest models in a stratified shuffled manner\n",
    "    skf = StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=1/4)\n",
    "    for idxs_train, idxs_test in skf.split(X1, y1):\n",
    "        # instantiate the random forest model\n",
    "        clf = LogisticRegression()\n",
    "        # fit the random forest model using Dataset #1\n",
    "        clf = clf.fit(X1.iloc[idxs_train], y1.iloc[idxs_train])\n",
    "\n",
    "        # predict on Dataset #2 correcting to all indices if requested\n",
    "        if pred_on_all:\n",
    "            idxs_test = range(X2.shape[0])\n",
    "        # derive the probabilities\n",
    "        proba = clf.predict_proba(X2.iloc[idxs_test])[:, clf.classes_ == 1]\n",
    "        probas.append(pd.Series(proba[:, 0], index=X2.index[idxs_test]))\n",
    "        # binarize into categorical predictions\n",
    "        proba_bin = 1 * (proba >= 0.50)\n",
    "        probas_bin.append(pd.Series(proba_bin[:, 0], index=X2.index[idxs_test]))\n",
    "        # retrieve the associated ground truth\n",
    "        truth = y2.iloc[idxs_test]\n",
    "        truths.append(truth.copy())\n",
    "\n",
    "        # compute subsequent AUROC and AUPRC related metrics\n",
    "        fpr, tpr, _ = roc_curve(truth, proba)\n",
    "        pre, rec, _ = precision_recall_curve(truth, proba)\n",
    "        fprs.append(fpr); tprs.append(tpr); pres.append(pre); recs.append(rec)\n",
    "        # save the relevant statistics\n",
    "        df_stat.loc[df_stat.shape[0]] = auc(fpr, tpr), auc(rec, pre)\n",
    "\n",
    "    # check the difference\n",
    "    for stat in df_stat.columns:\n",
    "        fig, ax = plt.subplots(figsize=[1, 4]); ax.grid(False)\n",
    "        sns.boxplot(y=df_stat[stat], linewidth=1.5, saturation=1, showfliers=False, linecolor='dodgerblue', color='skyblue')\n",
    "        sns.stripplot(y=df_stat[stat], linewidth=1.5, s=6, alpha=0.5, color='skyblue', edgecolor='dodgerblue')\n",
    "        ax.set_xlim(-0.75, 0.75); ax.set_ylabel(stat.upper())\n",
    "        print(stat.upper(), df_stat[stat].mean(), df_stat[stat].std() / np.sqrt(df_stat.shape[0])*1.96)\n",
    "\n",
    "    # plot the FPR, TPR\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for fpr, tpr in zip(fprs, tprs):\n",
    "        ax.plot(fpr, tpr, color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, fpr, tpr))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0, 1], color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "\n",
    "    # plot the precision recall\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for pre, rec in zip(pres, recs):\n",
    "        ax.plot(rec[::-1], pre[::-1], color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, rec[::-1], pre[::-1]))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0.5]*2, color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='Recall', ylabel='Precision')\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    # define the results\n",
    "    result = pd.DataFrame(columns=['Truth','PredProb'])\n",
    "    for proba, truth in zip(probas, truths):\n",
    "        result.loc[result.shape[0]] = '+', proba[truth == 1].mean()\n",
    "        result.loc[result.shape[0]] = '-', proba[truth == 0].mean()\n",
    "\n",
    "    # compare the average prediction probabilities\n",
    "    fig, ax = plt.subplots(figsize=[2, 4]); ax.grid(False)\n",
    "    sns.boxplot(x='Truth', y='PredProb', data=result, linewidth=1.5, saturation=1,\n",
    "                showfliers=False, linecolor='dodgerblue', color='skyblue',\n",
    "                order=['-', '+'], palette=['lightgray','skyblue'])\n",
    "    np.random.seed(0)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['dodgerblue'], order=['+'], alpha=0.6, s=6)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['grey'], order=['-'], alpha=0.6, s=6)\n",
    "    ax.set_xlim(-1, 2); ax.set_ylabel('Prediction Probability'); ax.set_xlabel('Ground Truth')\n",
    "    ax.get_children()[0].set_hatch('//')\n",
    "    ax.get_children()[0].set_edgecolor('grey')\n",
    "    for idx in range(1, 6):\n",
    "        ax.get_children()[idx].set_color('grey')\n",
    "\n",
    "    # report statistics\n",
    "    print('p-value for + vs. -:')\n",
    "    print(ss.mannwhitneyu(result.loc[result['Truth'] == '+', 'PredProb'], result.loc[result['Truth'] == '-', 'PredProb']))\n",
    "    print('average:')\n",
    "    print(df_stat.mean(0))\n",
    "    print('95% cis:')\n",
    "    print(df_stat.std(0) / np.sqrt(10) * 1.96)\n",
    "    return df_stat, probas, truths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209b3c0d-e920-4126-89e2-13c305823668",
   "metadata": {},
   "source": [
    "#### Fetal Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af65cff-77cf-49e1-83fb-476b8ed0d686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains(':TYPE_1_INNATE_T'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = False\n",
    "# perform predictions with all\n",
    "df_stat_fetal, _, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9096a6-f318-4762-8edf-1eddd16459c4",
   "metadata": {},
   "source": [
    "#### Fetal... --> COVID-19 and Adult Healthy Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f8c693-293d-40bc-9b4a-49a5799bfe3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_su2022_X.copy()\n",
    "X2 = X2.loc[~X2.index.str.endswith('nan')]\n",
    "X2 = X2.loc[~X2.index.str.endswith('CD8_Naive_14')]\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('CD8_Cytotoxic_3'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_covid, probas_covid, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8208e6b-370f-4e51-991b-5a043c2c3e0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_covid, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 2.5]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Adult PT and HD CD8+ T Cell States', ylabel='Type I Innate Score')\n",
    "# derive the kruskal wallis statistic\n",
    "ss.kruskal(*[df_plot['value'][df_plot['phenotype'] == x] for x in df_plot['phenotype'].unique()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2bc8a4-8831-419f-890e-f63f66e21b09",
   "metadata": {},
   "source": [
    "#### Fetal... --> Pan-Cancer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751f56b6-c102-4a61-8eed-23d92888fb8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_zheng2021_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('KIR'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_tumor, probas_tumor, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e28299-b222-4e5d-b939-5c885aab8319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_tumor, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 2.5]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Pan-Cancer CD8+ T Cell States', ylabel='Type I Innate Score')\n",
    "# derive the kruskal wallis statistic\n",
    "ss.kruskal(*[df_plot['value'][df_plot['phenotype'] == x] for x in df_plot['phenotype'].unique()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351743b7-114a-40ba-b2e0-390354c868ea",
   "metadata": {},
   "source": [
    "### Confirm Predictions with Transcriptomic Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c432ba8a-8de4-4678-83b5-8209e60c5737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the original H5AD file\n",
    "adata = sc.read_h5ad('../external_data/SUO_SCIENCE2022_FETAL/PAN.A01.v01.raw_count.20210429.NKT.embedding.abTCR.h5ad')\n",
    "# normalize the data\n",
    "sc.pp.normalize_total(adata, target_sum=1e6)\n",
    "sc.pp.log1p(adata)\n",
    "# can we isolate out the two populations?\n",
    "adata_ = adata[adata.obs['celltype_annotation'] == 'TYPE_1_INNATE_T'].copy()\n",
    "sc.pp.neighbors(adata_, use_rep='X_scvi', n_neighbors=30)\n",
    "sc.tl.umap(adata_)\n",
    "# write out the data\n",
    "adata_.write('../outs/fetal.toit.h5ad')\n",
    "\n",
    "# color on the phenotype\n",
    "adata_ = sc.read_h5ad('../outs/fetal.toit.h5ad')\n",
    "adata_.obs['phenotype'] = adata_.obs['phenotype'].astype(str)\n",
    "adata_.obs['phenotype'] = adata_.obs['phenotype'].str.replace('nan','Interm.')\n",
    "adata_.uns['phenotype_colors'] = [x for x in sns.color_palette('Set2', 3).as_hex()]\n",
    "sc.pl.umap(adata_, color=['phenotype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38602f58-de5f-4aba-b302-403896b58690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import to_rgb, to_hex\n",
    "# change colors\n",
    "colors = [list(to_rgb(x)) for x in adata_.uns['phenotype_colors']]\n",
    "colors_neo = []\n",
    "for color in colors:\n",
    "    color[-1] *= 2.00\n",
    "    color[0] *= 1.25\n",
    "    color[0] = min(1, color[0])\n",
    "    color[-1] = min(1, color[-1])\n",
    "    color = np.array(color) * 0.95\n",
    "    colors_neo.append(to_hex(color))\n",
    "adata_.uns['phenotype_colors'] = colors_neo\n",
    "sc.pl.umap(adata_, color=['phenotype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157ccc6-d49f-49a8-8a03-0ce471cf1507",
   "metadata": {},
   "source": [
    "#### KIR and MAIT -like Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33934ae1-c374-4f97-a5cf-c1e1914ea5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute the MAGIC imputed gene expression\n",
    "mdata_ = adata_.copy()\n",
    "sc.pp.filter_genes(mdata_, min_cells=1)\n",
    "sc.external.pp.magic(mdata_, random_state=0, t=3)\n",
    "# derive the signatures\n",
    "sc.tl.score_genes(mdata_, gene_list=genes_mait, score_name='score_MAIT', random_state=0, use_raw=False)\n",
    "sc.tl.score_genes(mdata_, gene_list=genes_kir, score_name='score_KIR', random_state=0, use_raw=False)\n",
    "# plot the signatures\n",
    "mdata_.obs[['score_MAIT','score_KIR']] -= mdata_.obs[['score_MAIT','score_KIR']].mean()\n",
    "mdata_.obs[['score_MAIT','score_KIR']] /= mdata_.obs[['score_MAIT','score_KIR']].std()\n",
    "# look at the scores but weighted accordingly\n",
    "for k in ['score_MAIT','score_KIR']:\n",
    "    vs = mdata_.obs[k].copy()\n",
    "    vmin, vmax = np.percentile(vs, 2), np.percentile(vs, 98)\n",
    "    sc.pl.umap(mdata_, color=[k], cmap='Blues', vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c50aab-ac63-4124-9265-5f338af28321",
   "metadata": {},
   "source": [
    "## Fetal... --> COVID-19 and Adult Healthy Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd14919-3fd3-44ea-920f-e73bf4aadf9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_su2022_X.copy()\n",
    "X2 = X2.loc[~X2.index.str.endswith('nan')]\n",
    "X2 = X2.loc[~X2.index.str.endswith('CD8_Naive_14')]\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('CD8_Cytotoxic_3'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_covid, probas_covid, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3466a805-8c10-4b40-83f8-789feda2a296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_covid, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Adult PT and HD CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6b4f29-c3ab-43d5-b12b-6f817e33f5ca",
   "metadata": {},
   "source": [
    "## Fetal... --> Pan-Cancer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a891a79-95e7-4d9d-b81e-893633be96ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_zheng2021_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('KIR'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_tumor, probas_tumor, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942a1943-225d-44ec-a416-86060d51bb6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_tumor, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Pan-Cancer CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2f9a53-22af-40b8-b896-d5b7d35b8daf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a function to interrogate the data\n",
    "def interrogate_with_globals():\n",
    "    # create statistics tracking dataframe\n",
    "    df_stat = pd.DataFrame(columns=['auroc','auprc','f1_score','balacc'])\n",
    "    # create tracking variables for downstream visualization and statistics\n",
    "    probas, probas_bin, truths = [], [], []\n",
    "    fprs, tprs, pres, recs = [], [], [], []\n",
    "    # train utilizing random forest models in a stratified shuffled manner\n",
    "    skf = StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=1/4)\n",
    "    for idxs_train, idxs_test in skf.split(X1, y1):\n",
    "        # instantiate the random forest model\n",
    "        clf = RandomForestClassifier(random_state=0, n_estimators=200)\n",
    "        # fit the random forest model using Dataset #1\n",
    "        clf = clf.fit(X1.iloc[idxs_train], y1.iloc[idxs_train])\n",
    "\n",
    "        # predict on Dataset #2 correcting to all indices if requested\n",
    "        if pred_on_all:\n",
    "            idxs_test = range(X2.shape[0])\n",
    "        # derive the probabilities\n",
    "        proba = clf.predict_proba(X2.iloc[idxs_test])[:, clf.classes_ == 1]\n",
    "        probas.append(pd.Series(proba[:, 0], index=X2.index[idxs_test]))\n",
    "        # binarize into categorical predictions\n",
    "        proba_bin = 1 * (proba >= 0.50)\n",
    "        probas_bin.append(pd.Series(proba_bin[:, 0], index=X2.index[idxs_test]))\n",
    "        # retrieve the associated ground truth\n",
    "        truth = y2.iloc[idxs_test]\n",
    "        truths.append(truth.copy())\n",
    "\n",
    "        # compute subsequent AUROC and AUPRC related metrics\n",
    "        fpr, tpr, _ = roc_curve(truth, proba)\n",
    "        pre, rec, _ = precision_recall_curve(truth, proba)\n",
    "        fprs.append(fpr); tprs.append(tpr); pres.append(pre); recs.append(rec)\n",
    "        # save the relevant statistics\n",
    "        df_stat.loc[df_stat.shape[0]] = auc(fpr, tpr), auc(rec, pre), \\\n",
    "                                        f1_score(truth, proba_bin, average='binary'), \\\n",
    "                                        balanced_accuracy_score(truth, proba_bin)\n",
    "\n",
    "    # check the difference\n",
    "    for stat in df_stat.columns:\n",
    "        fig, ax = plt.subplots(figsize=[1, 4]); ax.grid(False)\n",
    "        sns.boxplot(y=df_stat[stat], linewidth=1.5, saturation=1, showfliers=False, linecolor='dodgerblue', color='skyblue')\n",
    "        sns.stripplot(y=df_stat[stat], linewidth=1.5, s=6, alpha=0.5, color='skyblue', edgecolor='dodgerblue')\n",
    "        ax.set_xlim(-0.75, 0.75); ax.set_ylabel(stat.upper())\n",
    "        print(stat.upper(), df_stat[stat].mean(), df_stat[stat].std() / np.sqrt(df_stat.shape[0])*1.96)\n",
    "\n",
    "    # plot the FPR, TPR\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for fpr, tpr in zip(fprs, tprs):\n",
    "        ax.plot(fpr, tpr, color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, fpr, tpr))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0, 1], color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "\n",
    "    # plot the precision recall\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for pre, rec in zip(pres, recs):\n",
    "        ax.plot(rec[::-1], pre[::-1], color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, rec[::-1], pre[::-1]))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0.5]*2, color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='Recall', ylabel='Precision')\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    # define the results\n",
    "    result = pd.DataFrame(columns=['Truth','PredProb'])\n",
    "    for proba, truth in zip(probas, truths):\n",
    "        result.loc[result.shape[0]] = '+', proba[truth == 1].mean()\n",
    "        result.loc[result.shape[0]] = '-', proba[truth == 0].mean()\n",
    "\n",
    "    # compare the average prediction probabilities\n",
    "    fig, ax = plt.subplots(figsize=[2, 4]); ax.grid(False)\n",
    "    sns.boxplot(x='Truth', y='PredProb', data=result, linewidth=1.5, saturation=1,\n",
    "                showfliers=False, linecolor='dodgerblue', color='skyblue',\n",
    "                order=['-', '+'], palette=['lightgray','skyblue'])\n",
    "    np.random.seed(0)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['dodgerblue'], order=['+'], alpha=0.6, s=6)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['grey'], order=['-'], alpha=0.6, s=6)\n",
    "    ax.set_xlim(-1, 2); ax.set_ylabel('Prediction Probability'); ax.set_xlabel('Ground Truth')\n",
    "    ax.get_children()[0].set_hatch('//')\n",
    "    ax.get_children()[0].set_edgecolor('grey')\n",
    "    for idx in range(1, 6):\n",
    "        ax.get_children()[idx].set_color('grey')\n",
    "\n",
    "    # report statistics\n",
    "    print('p-value for + vs. -:')\n",
    "    print(ss.mannwhitneyu(result.loc[result['Truth'] == '+', 'PredProb'], result.loc[result['Truth'] == '-', 'PredProb']))\n",
    "    print('average:')\n",
    "    print(df_stat.mean(0))\n",
    "    print('95% cis:')\n",
    "    print(df_stat.std(0) / np.sqrt(10) * 1.96)\n",
    "    return df_stat, probas, truths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b9c5c8-4701-4ac0-b2c8-d47790066352",
   "metadata": {},
   "source": [
    "## Fetal Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4690393-afcf-49de-8f27-3291a9724c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains(':TYPE_1_INNATE_T'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = False\n",
    "# perform predictions with all\n",
    "df_stat_fetal, _, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709894ee-8139-49b1-96e9-07fa8880f587",
   "metadata": {},
   "source": [
    "## Fetal... --> COVID-19 and Adult Healthy Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e875022-7a7b-4652-b4e1-7e06bdff98bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_su2022_X.copy()\n",
    "X2 = X2.loc[~X2.index.str.endswith('nan')]\n",
    "X2 = X2.loc[~X2.index.str.endswith('CD8_Naive_14')]\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('CD8_Cytotoxic_3'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_covid, probas_covid, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e3a79-ec38-4279-8ca4-fcb7d38e0b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_covid, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Adult PT and HD CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e4f36c-dd59-4403-9097-a98f046dbfaf",
   "metadata": {},
   "source": [
    "## Fetal... --> Pan-Cancer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b693572a-3de5-44a7-a5d3-8cc85bb65461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_zheng2021_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('KIR'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_tumor, probas_tumor, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd0b83c-59a1-4ccd-9e1a-9b30cde39dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_tumor, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Pan-Cancer CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba25e8-7d27-4324-9498-12f42f57d53e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a function to interrogate the data\n",
    "def interrogate_with_globals():\n",
    "    # create statistics tracking dataframe\n",
    "    df_stat = pd.DataFrame(columns=['auroc','auprc','f1_score','balacc'])\n",
    "    # create tracking variables for downstream visualization and statistics\n",
    "    probas, probas_bin, truths = [], [], []\n",
    "    fprs, tprs, pres, recs = [], [], [], []\n",
    "    # train utilizing random forest models in a stratified shuffled manner\n",
    "    skf = StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=1/4)\n",
    "    for idxs_train, idxs_test in skf.split(X1, y1):\n",
    "        # instantiate the random forest model\n",
    "        clf = RandomForestClassifier(random_state=0, n_estimators=500)\n",
    "        # fit the random forest model using Dataset #1\n",
    "        clf = clf.fit(X1.iloc[idxs_train], y1.iloc[idxs_train])\n",
    "\n",
    "        # predict on Dataset #2 correcting to all indices if requested\n",
    "        if pred_on_all:\n",
    "            idxs_test = range(X2.shape[0])\n",
    "        # derive the probabilities\n",
    "        proba = clf.predict_proba(X2.iloc[idxs_test])[:, clf.classes_ == 1]\n",
    "        probas.append(pd.Series(proba[:, 0], index=X2.index[idxs_test]))\n",
    "        # binarize into categorical predictions\n",
    "        proba_bin = 1 * (proba >= 0.50)\n",
    "        probas_bin.append(pd.Series(proba_bin[:, 0], index=X2.index[idxs_test]))\n",
    "        # retrieve the associated ground truth\n",
    "        truth = y2.iloc[idxs_test]\n",
    "        truths.append(truth.copy())\n",
    "\n",
    "        # compute subsequent AUROC and AUPRC related metrics\n",
    "        fpr, tpr, _ = roc_curve(truth, proba)\n",
    "        pre, rec, _ = precision_recall_curve(truth, proba)\n",
    "        fprs.append(fpr); tprs.append(tpr); pres.append(pre); recs.append(rec)\n",
    "        # save the relevant statistics\n",
    "        df_stat.loc[df_stat.shape[0]] = auc(fpr, tpr), auc(rec, pre), \\\n",
    "                                        f1_score(truth, proba_bin, average='binary'), \\\n",
    "                                        balanced_accuracy_score(truth, proba_bin)\n",
    "\n",
    "    # check the difference\n",
    "    for stat in df_stat.columns:\n",
    "        fig, ax = plt.subplots(figsize=[1, 4]); ax.grid(False)\n",
    "        sns.boxplot(y=df_stat[stat], linewidth=1.5, saturation=1, showfliers=False, linecolor='dodgerblue', color='skyblue')\n",
    "        sns.stripplot(y=df_stat[stat], linewidth=1.5, s=6, alpha=0.5, color='skyblue', edgecolor='dodgerblue')\n",
    "        ax.set_xlim(-0.75, 0.75); ax.set_ylabel(stat.upper())\n",
    "        print(stat.upper(), df_stat[stat].mean(), df_stat[stat].std() / np.sqrt(df_stat.shape[0])*1.96)\n",
    "\n",
    "    # plot the FPR, TPR\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for fpr, tpr in zip(fprs, tprs):\n",
    "        ax.plot(fpr, tpr, color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, fpr, tpr))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0, 1], color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "\n",
    "    # plot the precision recall\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for pre, rec in zip(pres, recs):\n",
    "        ax.plot(rec[::-1], pre[::-1], color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, rec[::-1], pre[::-1]))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0.5]*2, color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='Recall', ylabel='Precision')\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    # define the results\n",
    "    result = pd.DataFrame(columns=['Truth','PredProb'])\n",
    "    for proba, truth in zip(probas, truths):\n",
    "        result.loc[result.shape[0]] = '+', proba[truth == 1].mean()\n",
    "        result.loc[result.shape[0]] = '-', proba[truth == 0].mean()\n",
    "\n",
    "    # compare the average prediction probabilities\n",
    "    fig, ax = plt.subplots(figsize=[2, 4]); ax.grid(False)\n",
    "    sns.boxplot(x='Truth', y='PredProb', data=result, linewidth=1.5, saturation=1,\n",
    "                showfliers=False, linecolor='dodgerblue', color='skyblue',\n",
    "                order=['-', '+'], palette=['lightgray','skyblue'])\n",
    "    np.random.seed(0)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['dodgerblue'], order=['+'], alpha=0.6, s=6)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['grey'], order=['-'], alpha=0.6, s=6)\n",
    "    ax.set_xlim(-1, 2); ax.set_ylabel('Prediction Probability'); ax.set_xlabel('Ground Truth')\n",
    "    ax.get_children()[0].set_hatch('//')\n",
    "    ax.get_children()[0].set_edgecolor('grey')\n",
    "    for idx in range(1, 6):\n",
    "        ax.get_children()[idx].set_color('grey')\n",
    "\n",
    "    # report statistics\n",
    "    print('p-value for + vs. -:')\n",
    "    print(ss.mannwhitneyu(result.loc[result['Truth'] == '+', 'PredProb'], result.loc[result['Truth'] == '-', 'PredProb']))\n",
    "    print('average:')\n",
    "    print(df_stat.mean(0))\n",
    "    print('95% cis:')\n",
    "    print(df_stat.std(0) / np.sqrt(10) * 1.96)\n",
    "    return df_stat, probas, truths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a824d28-e80f-42ef-9d8b-fe0b131ad761",
   "metadata": {},
   "source": [
    "## Fetal Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410d5cc1-5fef-4539-9454-db75ca2f4a07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains(':TYPE_1_INNATE_T'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = False\n",
    "# perform predictions with all\n",
    "df_stat_fetal, _, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838cbc1c-bc81-4e83-9926-c3f7ea7bb40d",
   "metadata": {},
   "source": [
    "## Fetal... --> COVID-19 and Adult Healthy Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e66ea-2cb3-4d75-9f11-ee6350f07db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_su2022_X.copy()\n",
    "X2 = X2.loc[~X2.index.str.endswith('nan')]\n",
    "X2 = X2.loc[~X2.index.str.endswith('CD8_Naive_14')]\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('CD8_Cytotoxic_3'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_covid, probas_covid, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d3d8fe-42ad-491d-9817-f678fa44b1d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_covid, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Adult PT and HD CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3d33e6-8097-4a1e-9216-3ada6225d354",
   "metadata": {},
   "source": [
    "## Fetal... --> Pan-Cancer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccb1a67-eeb6-49f2-b08b-5ccb5cbc3ca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_zheng2021_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('KIR'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_tumor, probas_tumor, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df6727-62ed-459a-a881-aa4f35c957a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_tumor, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Pan-Cancer CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067ca323-7473-40c1-ad23-7a6650545244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67d07ed1-1810-4ae8-a9b8-59b871347f89",
   "metadata": {},
   "source": [
    "## Fetal Donors (Suo and Dann et al. 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad22f0d5-f913-42fd-927d-532f065a3137",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# define the minimum number of cells\n",
    "min_cells = 4\n",
    "# get the tag, keeping only pairs that have at least min_cells cells\n",
    "clusters = ['CD8+T','TYPE_1_INNATE_T']\n",
    "mask = results_tcr['SUO_SCIENCE2022_FETAL']['celltype_annotation'].isin(clusters)\n",
    "data = results_tcr['SUO_SCIENCE2022_FETAL'].loc[mask, ['donor','celltype_annotation','TRB']].astype(str).copy()\n",
    "data['tag'] = data[['donor','celltype_annotation']].astype(str).agg(':'.join, axis=1)\n",
    "# filter the data more harshly because less assured of quality\n",
    "data['TRB'][~data['TRB'].isin(a_trb.obs.index)] = np.nan\n",
    "data = data.dropna(subset=['TRB'])\n",
    "counts = data['tag'].value_counts(); tags = counts.index[counts >= min_cells]\n",
    "# compile the Xs\n",
    "Xs = []\n",
    "for tag in tqdm(tags):\n",
    "    trbs = data.loc[data['tag'] == tag, 'TRB']\n",
    "    mask = trbs[trbs.isin(a_trb.obs.index)]\n",
    "    X_ = pd.Series(a_trb[mask].X.mean(0), name=tag)\n",
    "    Xs.append(X_)\n",
    "og_trb_suo2022_X = pd.concat(Xs, axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014a94e0-bbf7-4fce-8783-b991b00ecc5d",
   "metadata": {},
   "source": [
    "## Adults with COVID-19 and Healthy Donors (Su, Yuan, and Chen et al. 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027de226-0757-4c3d-81c9-1ff0c8fb91ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the tag, keeping only pairs that have at least min_cells cells\n",
    "mask = ~results_tcr['SU_CELL2022_COVID19']['phenotype_leiden'].isna()\n",
    "data = results_tcr['SU_CELL2022_COVID19'][['sample','phenotype_leiden','TRB']].astype(str).copy()\n",
    "data['tag'] = data[['sample','phenotype_leiden']].astype(str).agg(':'.join, axis=1)\n",
    "# filter the data more harshly because less assured of quality\n",
    "data['TRB'][~data['TRB'].isin(a_trb.obs.index)] = np.nan\n",
    "data = data.dropna(subset=['TRB'])\n",
    "counts = data['tag'].value_counts(); tags = counts.index[counts >= min_cells]\n",
    "# compile the Xs\n",
    "Xs = []\n",
    "for tag in tqdm(tags):\n",
    "    trbs = data.loc[data['tag'] == tag, 'TRB']\n",
    "    mask = trbs[trbs.isin(a_trb.obs.index)]\n",
    "    X_ = pd.Series(a_trb[mask].X.mean(0), name=tag)\n",
    "    Xs.append(X_)\n",
    "og_trb_su2022_X = pd.concat(Xs, axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f77f01d-5528-4c15-bf28-952ff1c742f0",
   "metadata": {},
   "source": [
    "## Pan-Cancer Types (Zheng, Qin, and Si et al. 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d6be5-8827-4dac-af32-405036c13f62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the tag, keeping only pairs that have at least min_cells cells\n",
    "mask = results_tcr['ZHENG_SCIENCE2021_PANCAN']['TcellType'] == 'CD8'\n",
    "data = results_tcr['ZHENG_SCIENCE2021_PANCAN'].loc[mask, ['patient','cluster.name','TRB']].astype(str).copy()\n",
    "data['tag'] = data[['patient','cluster.name']].astype(str).agg(':'.join, axis=1)\n",
    "# filter the data more harshly because less assured of quality\n",
    "data['TRB'][~data['TRB'].isin(a_trb.obs.index)] = np.nan\n",
    "data = data.dropna(subset=['TRB'])\n",
    "counts = data['tag'].value_counts(); tags = counts.index[counts >= min_cells]\n",
    "# compile the Xs\n",
    "Xs = []\n",
    "for tag in tqdm(tags):\n",
    "    trbs = data.loc[data['tag'] == tag, 'TRB']\n",
    "    mask = trbs[trbs.isin(a_trb.obs.index)]\n",
    "    X_ = pd.Series(a_trb[mask].X.mean(0), name=tag)\n",
    "    Xs.append(X_)\n",
    "og_trb_zheng2021_X = pd.concat(Xs, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89cf98a-148e-4a9a-aed9-8a0aef7c7619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# define a function to interrogate the data\n",
    "def interrogate_with_globals():\n",
    "    # create statistics tracking dataframe\n",
    "    df_stat = pd.DataFrame(columns=['auroc','auprc','f1_score','balacc'])\n",
    "    # create tracking variables for downstream visualization and statistics\n",
    "    probas, probas_bin, truths = [], [], []\n",
    "    fprs, tprs, pres, recs = [], [], [], []\n",
    "    # train utilizing random forest models in a stratified shuffled manner\n",
    "    skf = StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=1/4)\n",
    "    for idxs_train, idxs_test in skf.split(X1, y1):\n",
    "        # instantiate the random forest model\n",
    "        clf = LogisticRegression()\n",
    "        # fit the random forest model using Dataset #1\n",
    "        clf = clf.fit(X1.iloc[idxs_train], y1.iloc[idxs_train])\n",
    "\n",
    "        # predict on Dataset #2 correcting to all indices if requested\n",
    "        if pred_on_all:\n",
    "            idxs_test = range(X2.shape[0])\n",
    "        # derive the probabilities\n",
    "        proba = clf.predict_proba(X2.iloc[idxs_test])[:, clf.classes_ == 1]\n",
    "        probas.append(pd.Series(proba[:, 0], index=X2.index[idxs_test]))\n",
    "        # binarize into categorical predictions\n",
    "        proba_bin = 1 * (proba >= 0.50)\n",
    "        probas_bin.append(pd.Series(proba_bin[:, 0], index=X2.index[idxs_test]))\n",
    "        # retrieve the associated ground truth\n",
    "        truth = y2.iloc[idxs_test]\n",
    "        truths.append(truth.copy())\n",
    "\n",
    "        # compute subsequent AUROC and AUPRC related metrics\n",
    "        fpr, tpr, _ = roc_curve(truth, proba)\n",
    "        pre, rec, _ = precision_recall_curve(truth, proba)\n",
    "        fprs.append(fpr); tprs.append(tpr); pres.append(pre); recs.append(rec)\n",
    "        # save the relevant statistics\n",
    "        df_stat.loc[df_stat.shape[0]] = auc(fpr, tpr), auc(rec, pre), \\\n",
    "                                        f1_score(truth, proba_bin, average='binary'), \\\n",
    "                                        balanced_accuracy_score(truth, proba_bin)\n",
    "\n",
    "    # check the difference\n",
    "    for stat in df_stat.columns:\n",
    "        fig, ax = plt.subplots(figsize=[1, 4]); ax.grid(False)\n",
    "        sns.boxplot(y=df_stat[stat], linewidth=1.5, saturation=1, showfliers=False, linecolor='dodgerblue', color='skyblue')\n",
    "        sns.stripplot(y=df_stat[stat], linewidth=1.5, s=6, alpha=0.5, color='skyblue', edgecolor='dodgerblue')\n",
    "        ax.set_xlim(-0.75, 0.75); ax.set_ylabel(stat.upper())\n",
    "        print(stat.upper(), df_stat[stat].mean(), df_stat[stat].std() / np.sqrt(df_stat.shape[0])*1.96)\n",
    "\n",
    "    # plot the FPR, TPR\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for fpr, tpr in zip(fprs, tprs):\n",
    "        ax.plot(fpr, tpr, color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, fpr, tpr))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0, 1], color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "\n",
    "    # plot the precision recall\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for pre, rec in zip(pres, recs):\n",
    "        ax.plot(rec[::-1], pre[::-1], color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, rec[::-1], pre[::-1]))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0.5]*2, color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='Recall', ylabel='Precision')\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    # define the results\n",
    "    result = pd.DataFrame(columns=['Truth','PredProb'])\n",
    "    for proba, truth in zip(probas, truths):\n",
    "        result.loc[result.shape[0]] = '+', proba[truth == 1].mean()\n",
    "        result.loc[result.shape[0]] = '-', proba[truth == 0].mean()\n",
    "\n",
    "    # compare the average prediction probabilities\n",
    "    fig, ax = plt.subplots(figsize=[2, 4]); ax.grid(False)\n",
    "    sns.boxplot(x='Truth', y='PredProb', data=result, linewidth=1.5, saturation=1,\n",
    "                showfliers=False, linecolor='dodgerblue', color='skyblue',\n",
    "                order=['-', '+'], palette=['lightgray','skyblue'])\n",
    "    np.random.seed(0)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['dodgerblue'], order=['+'], alpha=0.6, s=6)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['grey'], order=['-'], alpha=0.6, s=6)\n",
    "    ax.set_xlim(-1, 2); ax.set_ylabel('Prediction Probability'); ax.set_xlabel('Ground Truth')\n",
    "    ax.get_children()[0].set_hatch('//')\n",
    "    ax.get_children()[0].set_edgecolor('grey')\n",
    "    for idx in range(1, 6):\n",
    "        ax.get_children()[idx].set_color('grey')\n",
    "\n",
    "    # report statistics\n",
    "    print('p-value for + vs. -:')\n",
    "    print(ss.mannwhitneyu(result.loc[result['Truth'] == '+', 'PredProb'], result.loc[result['Truth'] == '-', 'PredProb']))\n",
    "    print('average:')\n",
    "    print(df_stat.mean(0))\n",
    "    print('95% cis:')\n",
    "    print(df_stat.std(0) / np.sqrt(10) * 1.96)\n",
    "    return df_stat, probas, truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093fa08d-1d0c-47d7-a05b-e8bd40fff91f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfb78b7-62ff-4434-b764-202e4830a10c",
   "metadata": {},
   "source": [
    "## Fetal Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3b9ef5-04e5-4a02-8ea4-0a8546ae9452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains(':TYPE_1_INNATE_T'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = False\n",
    "# perform predictions with all\n",
    "df_stat_fetal, _, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d21c06-ad9f-44cb-b8bd-05d9d7b40dd6",
   "metadata": {},
   "source": [
    "## Fetal... --> COVID-19 and Adult Healthy Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65bb0bb-5a29-47e7-abe8-0c26b184aedb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_su2022_X.copy()\n",
    "X2 = X2.loc[~X2.index.str.endswith('nan')]\n",
    "X2 = X2.loc[~X2.index.str.endswith('CD8_Naive_14')]\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('CD8_Cytotoxic_3'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_covid, probas_covid, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ea8639-8451-42ae-9c5f-47ea9f09b835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_covid, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Adult PT and HD CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f95827-ef89-4cfe-9f5c-5a2c59f0cdf8",
   "metadata": {},
   "source": [
    "## Fetal... --> Pan-Cancer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1867a8f6-60d4-4362-a7b1-bb7b1bf8e6e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_zheng2021_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('KIR'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_tumor, probas_tumor, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0777202f-4021-4200-945d-42e59397d902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_tumor, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Pan-Cancer CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263232bf-6701-4d1f-bea0-8bc73074f693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a function to interrogate the data\n",
    "def interrogate_with_globals():\n",
    "    # create statistics tracking dataframe\n",
    "    df_stat = pd.DataFrame(columns=['auroc','auprc','f1_score','balacc'])\n",
    "    # create tracking variables for downstream visualization and statistics\n",
    "    probas, probas_bin, truths = [], [], []\n",
    "    fprs, tprs, pres, recs = [], [], [], []\n",
    "    # train utilizing random forest models in a stratified shuffled manner\n",
    "    skf = StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=1/4)\n",
    "    for idxs_train, idxs_test in skf.split(X1, y1):\n",
    "        # instantiate the random forest model\n",
    "        clf = RandomForestClassifier(random_state=0, n_estimators=100)\n",
    "        # fit the random forest model using Dataset #1\n",
    "        clf = clf.fit(X1.iloc[idxs_train], y1.iloc[idxs_train])\n",
    "\n",
    "        # predict on Dataset #2 correcting to all indices if requested\n",
    "        if pred_on_all:\n",
    "            idxs_test = range(X2.shape[0])\n",
    "        # derive the probabilities\n",
    "        proba = clf.predict_proba(X2.iloc[idxs_test])[:, clf.classes_ == 1]\n",
    "        probas.append(pd.Series(proba[:, 0], index=X2.index[idxs_test]))\n",
    "        # binarize into categorical predictions\n",
    "        proba_bin = 1 * (proba >= 0.50)\n",
    "        probas_bin.append(pd.Series(proba_bin[:, 0], index=X2.index[idxs_test]))\n",
    "        # retrieve the associated ground truth\n",
    "        truth = y2.iloc[idxs_test]\n",
    "        truths.append(truth.copy())\n",
    "\n",
    "        # compute subsequent AUROC and AUPRC related metrics\n",
    "        fpr, tpr, _ = roc_curve(truth, proba)\n",
    "        pre, rec, _ = precision_recall_curve(truth, proba)\n",
    "        fprs.append(fpr); tprs.append(tpr); pres.append(pre); recs.append(rec)\n",
    "        # save the relevant statistics\n",
    "        df_stat.loc[df_stat.shape[0]] = auc(fpr, tpr), auc(rec, pre), \\\n",
    "                                        f1_score(truth, proba_bin, average='binary'), \\\n",
    "                                        balanced_accuracy_score(truth, proba_bin)\n",
    "\n",
    "    # check the difference\n",
    "    for stat in df_stat.columns:\n",
    "        fig, ax = plt.subplots(figsize=[1, 4]); ax.grid(False)\n",
    "        sns.boxplot(y=df_stat[stat], linewidth=1.5, saturation=1, showfliers=False, linecolor='dodgerblue', color='skyblue')\n",
    "        sns.stripplot(y=df_stat[stat], linewidth=1.5, s=6, alpha=0.5, color='skyblue', edgecolor='dodgerblue')\n",
    "        ax.set_xlim(-0.75, 0.75); ax.set_ylabel(stat.upper())\n",
    "        print(stat.upper(), df_stat[stat].mean(), df_stat[stat].std() / np.sqrt(df_stat.shape[0])*1.96)\n",
    "\n",
    "    # plot the FPR, TPR\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for fpr, tpr in zip(fprs, tprs):\n",
    "        ax.plot(fpr, tpr, color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, fpr, tpr))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0, 1], color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "\n",
    "    # plot the precision recall\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for pre, rec in zip(pres, recs):\n",
    "        ax.plot(rec[::-1], pre[::-1], color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, rec[::-1], pre[::-1]))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0.5]*2, color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='Recall', ylabel='Precision')\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    # define the results\n",
    "    result = pd.DataFrame(columns=['Truth','PredProb'])\n",
    "    for proba, truth in zip(probas, truths):\n",
    "        result.loc[result.shape[0]] = '+', proba[truth == 1].mean()\n",
    "        result.loc[result.shape[0]] = '-', proba[truth == 0].mean()\n",
    "\n",
    "    # compare the average prediction probabilities\n",
    "    fig, ax = plt.subplots(figsize=[2, 4]); ax.grid(False)\n",
    "    sns.boxplot(x='Truth', y='PredProb', data=result, linewidth=1.5, saturation=1,\n",
    "                showfliers=False, linecolor='dodgerblue', color='skyblue',\n",
    "                order=['-', '+'], palette=['lightgray','skyblue'])\n",
    "    np.random.seed(0)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['dodgerblue'], order=['+'], alpha=0.6, s=6)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['grey'], order=['-'], alpha=0.6, s=6)\n",
    "    ax.set_xlim(-1, 2); ax.set_ylabel('Prediction Probability'); ax.set_xlabel('Ground Truth')\n",
    "    ax.get_children()[0].set_hatch('//')\n",
    "    ax.get_children()[0].set_edgecolor('grey')\n",
    "    for idx in range(1, 6):\n",
    "        ax.get_children()[idx].set_color('grey')\n",
    "\n",
    "    # report statistics\n",
    "    print('p-value for + vs. -:')\n",
    "    print(ss.mannwhitneyu(result.loc[result['Truth'] == '+', 'PredProb'], result.loc[result['Truth'] == '-', 'PredProb']))\n",
    "    print('average:')\n",
    "    print(df_stat.mean(0))\n",
    "    print('95% cis:')\n",
    "    print(df_stat.std(0) / np.sqrt(10) * 1.96)\n",
    "    return df_stat, probas, truths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fb05dd-1016-4dda-b63e-5a4460296e0d",
   "metadata": {},
   "source": [
    "## Fetal Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa4b26-4f23-4e28-95ae-a20384229922",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains(':TYPE_1_INNATE_T'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = False\n",
    "# perform predictions with all\n",
    "df_stat_fetal, _, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83248d3e-644c-40a8-a4b1-36b123464102",
   "metadata": {},
   "source": [
    "## Fetal... --> COVID-19 and Adult Healthy Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cf4353-b0e6-493e-ab81-ff99a8b0f71d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_su2022_X.copy()\n",
    "X2 = X2.loc[~X2.index.str.endswith('nan')]\n",
    "X2 = X2.loc[~X2.index.str.endswith('CD8_Naive_14')]\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('CD8_Cytotoxic_3'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_covid, probas_covid, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edade1e-560f-4855-8675-d22e3629b997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_covid, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Adult PT and HD CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53b63ee-d760-4fdd-af05-0d68673dafe9",
   "metadata": {},
   "source": [
    "## Fetal... --> Pan-Cancer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5f0276-a7a6-4a69-a575-99869030cc30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_zheng2021_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('KIR'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_tumor, probas_tumor, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f8838-e734-4628-9fbd-c996c0561fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_tumor, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Pan-Cancer CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0d7be4-c957-4fed-b6b1-308dedc2c73d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a function to interrogate the data\n",
    "def interrogate_with_globals():\n",
    "    # create statistics tracking dataframe\n",
    "    df_stat = pd.DataFrame(columns=['auroc','auprc','f1_score','balacc'])\n",
    "    # create tracking variables for downstream visualization and statistics\n",
    "    probas, probas_bin, truths = [], [], []\n",
    "    fprs, tprs, pres, recs = [], [], [], []\n",
    "    # train utilizing random forest models in a stratified shuffled manner\n",
    "    skf = StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=1/4)\n",
    "    for idxs_train, idxs_test in skf.split(X1, y1):\n",
    "        # instantiate the random forest model\n",
    "        clf = RandomForestClassifier(random_state=0, n_estimators=200)\n",
    "        # fit the random forest model using Dataset #1\n",
    "        clf = clf.fit(X1.iloc[idxs_train], y1.iloc[idxs_train])\n",
    "\n",
    "        # predict on Dataset #2 correcting to all indices if requested\n",
    "        if pred_on_all:\n",
    "            idxs_test = range(X2.shape[0])\n",
    "        # derive the probabilities\n",
    "        proba = clf.predict_proba(X2.iloc[idxs_test])[:, clf.classes_ == 1]\n",
    "        probas.append(pd.Series(proba[:, 0], index=X2.index[idxs_test]))\n",
    "        # binarize into categorical predictions\n",
    "        proba_bin = 1 * (proba >= 0.50)\n",
    "        probas_bin.append(pd.Series(proba_bin[:, 0], index=X2.index[idxs_test]))\n",
    "        # retrieve the associated ground truth\n",
    "        truth = y2.iloc[idxs_test]\n",
    "        truths.append(truth.copy())\n",
    "\n",
    "        # compute subsequent AUROC and AUPRC related metrics\n",
    "        fpr, tpr, _ = roc_curve(truth, proba)\n",
    "        pre, rec, _ = precision_recall_curve(truth, proba)\n",
    "        fprs.append(fpr); tprs.append(tpr); pres.append(pre); recs.append(rec)\n",
    "        # save the relevant statistics\n",
    "        df_stat.loc[df_stat.shape[0]] = auc(fpr, tpr), auc(rec, pre), \\\n",
    "                                        f1_score(truth, proba_bin, average='binary'), \\\n",
    "                                        balanced_accuracy_score(truth, proba_bin)\n",
    "\n",
    "    # check the difference\n",
    "    for stat in df_stat.columns:\n",
    "        fig, ax = plt.subplots(figsize=[1, 4]); ax.grid(False)\n",
    "        sns.boxplot(y=df_stat[stat], linewidth=1.5, saturation=1, showfliers=False, linecolor='dodgerblue', color='skyblue')\n",
    "        sns.stripplot(y=df_stat[stat], linewidth=1.5, s=6, alpha=0.5, color='skyblue', edgecolor='dodgerblue')\n",
    "        ax.set_xlim(-0.75, 0.75); ax.set_ylabel(stat.upper())\n",
    "        print(stat.upper(), df_stat[stat].mean(), df_stat[stat].std() / np.sqrt(df_stat.shape[0])*1.96)\n",
    "\n",
    "    # plot the FPR, TPR\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for fpr, tpr in zip(fprs, tprs):\n",
    "        ax.plot(fpr, tpr, color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, fpr, tpr))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0, 1], color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "\n",
    "    # plot the precision recall\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for pre, rec in zip(pres, recs):\n",
    "        ax.plot(rec[::-1], pre[::-1], color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, rec[::-1], pre[::-1]))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0.5]*2, color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='Recall', ylabel='Precision')\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    # define the results\n",
    "    result = pd.DataFrame(columns=['Truth','PredProb'])\n",
    "    for proba, truth in zip(probas, truths):\n",
    "        result.loc[result.shape[0]] = '+', proba[truth == 1].mean()\n",
    "        result.loc[result.shape[0]] = '-', proba[truth == 0].mean()\n",
    "\n",
    "    # compare the average prediction probabilities\n",
    "    fig, ax = plt.subplots(figsize=[2, 4]); ax.grid(False)\n",
    "    sns.boxplot(x='Truth', y='PredProb', data=result, linewidth=1.5, saturation=1,\n",
    "                showfliers=False, linecolor='dodgerblue', color='skyblue',\n",
    "                order=['-', '+'], palette=['lightgray','skyblue'])\n",
    "    np.random.seed(0)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['dodgerblue'], order=['+'], alpha=0.6, s=6)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['grey'], order=['-'], alpha=0.6, s=6)\n",
    "    ax.set_xlim(-1, 2); ax.set_ylabel('Prediction Probability'); ax.set_xlabel('Ground Truth')\n",
    "    ax.get_children()[0].set_hatch('//')\n",
    "    ax.get_children()[0].set_edgecolor('grey')\n",
    "    for idx in range(1, 6):\n",
    "        ax.get_children()[idx].set_color('grey')\n",
    "\n",
    "    # report statistics\n",
    "    print('p-value for + vs. -:')\n",
    "    print(ss.mannwhitneyu(result.loc[result['Truth'] == '+', 'PredProb'], result.loc[result['Truth'] == '-', 'PredProb']))\n",
    "    print('average:')\n",
    "    print(df_stat.mean(0))\n",
    "    print('95% cis:')\n",
    "    print(df_stat.std(0) / np.sqrt(10) * 1.96)\n",
    "    return df_stat, probas, truths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd75845-ab84-4838-9143-16bac63b79a6",
   "metadata": {},
   "source": [
    "## Fetal Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ac73c4-3bea-43a2-aa51-0faf78f26fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains(':TYPE_1_INNATE_T'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = False\n",
    "# perform predictions with all\n",
    "df_stat_fetal, _, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1bf71c-6933-4e77-bfe3-8a8f93d4e020",
   "metadata": {},
   "source": [
    "## Fetal... --> COVID-19 and Adult Healthy Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c19b6-03c9-48bd-a8b1-f02438b08da5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_su2022_X.copy()\n",
    "X2 = X2.loc[~X2.index.str.endswith('nan')]\n",
    "X2 = X2.loc[~X2.index.str.endswith('CD8_Naive_14')]\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('CD8_Cytotoxic_3'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_covid, probas_covid, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781108c6-7b50-42e9-8382-c2f10a83de67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_covid, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Adult PT and HD CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79b9bdd-ca29-4a76-8ba9-25d0494f7bee",
   "metadata": {},
   "source": [
    "## Fetal... --> Pan-Cancer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8418843-e6f1-41b9-b83e-71f56f6b8227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_zheng2021_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('KIR'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_tumor, probas_tumor, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d59773-d3a4-47fb-8973-5b0f08562b17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_tumor, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Pan-Cancer CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e43159d-f6a2-4718-b8ab-283fa8c82003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a function to interrogate the data\n",
    "def interrogate_with_globals():\n",
    "    # create statistics tracking dataframe\n",
    "    df_stat = pd.DataFrame(columns=['auroc','auprc','f1_score','balacc'])\n",
    "    # create tracking variables for downstream visualization and statistics\n",
    "    probas, probas_bin, truths = [], [], []\n",
    "    fprs, tprs, pres, recs = [], [], [], []\n",
    "    # train utilizing random forest models in a stratified shuffled manner\n",
    "    skf = StratifiedShuffleSplit(n_splits=10, random_state=0, test_size=1/4)\n",
    "    for idxs_train, idxs_test in skf.split(X1, y1):\n",
    "        # instantiate the random forest model\n",
    "        clf = RandomForestClassifier(random_state=0, n_estimators=500)\n",
    "        # fit the random forest model using Dataset #1\n",
    "        clf = clf.fit(X1.iloc[idxs_train], y1.iloc[idxs_train])\n",
    "\n",
    "        # predict on Dataset #2 correcting to all indices if requested\n",
    "        if pred_on_all:\n",
    "            idxs_test = range(X2.shape[0])\n",
    "        # derive the probabilities\n",
    "        proba = clf.predict_proba(X2.iloc[idxs_test])[:, clf.classes_ == 1]\n",
    "        probas.append(pd.Series(proba[:, 0], index=X2.index[idxs_test]))\n",
    "        # binarize into categorical predictions\n",
    "        proba_bin = 1 * (proba >= 0.50)\n",
    "        probas_bin.append(pd.Series(proba_bin[:, 0], index=X2.index[idxs_test]))\n",
    "        # retrieve the associated ground truth\n",
    "        truth = y2.iloc[idxs_test]\n",
    "        truths.append(truth.copy())\n",
    "\n",
    "        # compute subsequent AUROC and AUPRC related metrics\n",
    "        fpr, tpr, _ = roc_curve(truth, proba)\n",
    "        pre, rec, _ = precision_recall_curve(truth, proba)\n",
    "        fprs.append(fpr); tprs.append(tpr); pres.append(pre); recs.append(rec)\n",
    "        # save the relevant statistics\n",
    "        df_stat.loc[df_stat.shape[0]] = auc(fpr, tpr), auc(rec, pre), \\\n",
    "                                        f1_score(truth, proba_bin, average='binary'), \\\n",
    "                                        balanced_accuracy_score(truth, proba_bin)\n",
    "\n",
    "    # check the difference\n",
    "    for stat in df_stat.columns:\n",
    "        fig, ax = plt.subplots(figsize=[1, 4]); ax.grid(False)\n",
    "        sns.boxplot(y=df_stat[stat], linewidth=1.5, saturation=1, showfliers=False, linecolor='dodgerblue', color='skyblue')\n",
    "        sns.stripplot(y=df_stat[stat], linewidth=1.5, s=6, alpha=0.5, color='skyblue', edgecolor='dodgerblue')\n",
    "        ax.set_xlim(-0.75, 0.75); ax.set_ylabel(stat.upper())\n",
    "        print(stat.upper(), df_stat[stat].mean(), df_stat[stat].std() / np.sqrt(df_stat.shape[0])*1.96)\n",
    "\n",
    "    # plot the FPR, TPR\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for fpr, tpr in zip(fprs, tprs):\n",
    "        ax.plot(fpr, tpr, color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, fpr, tpr))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0, 1], color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='False Positive Rate', ylabel='True Positive Rate')\n",
    "\n",
    "    # plot the precision recall\n",
    "    fig, ax = plt.subplots(figsize=[4, 4]); ax.grid(False)\n",
    "    xl = np.arange(0, 1.01, 0.01); yls = []\n",
    "    for pre, rec in zip(pres, recs):\n",
    "        ax.plot(rec[::-1], pre[::-1], color='skyblue', linestyle='--', lw=1)\n",
    "        yls.append(np.interp(xl, rec[::-1], pre[::-1]))\n",
    "    yl = np.vstack(yls).mean(0)\n",
    "    ax.plot(xl, yl, color='dodgerblue', lw=2)\n",
    "    ax.plot([0, 1], [0.5]*2, color='lightgray', linestyle='dotted')\n",
    "    ax.set(xlabel='Recall', ylabel='Precision')\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    # define the results\n",
    "    result = pd.DataFrame(columns=['Truth','PredProb'])\n",
    "    for proba, truth in zip(probas, truths):\n",
    "        result.loc[result.shape[0]] = '+', proba[truth == 1].mean()\n",
    "        result.loc[result.shape[0]] = '-', proba[truth == 0].mean()\n",
    "\n",
    "    # compare the average prediction probabilities\n",
    "    fig, ax = plt.subplots(figsize=[2, 4]); ax.grid(False)\n",
    "    sns.boxplot(x='Truth', y='PredProb', data=result, linewidth=1.5, saturation=1,\n",
    "                showfliers=False, linecolor='dodgerblue', color='skyblue',\n",
    "                order=['-', '+'], palette=['lightgray','skyblue'])\n",
    "    np.random.seed(0)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['dodgerblue'], order=['+'], alpha=0.6, s=6)\n",
    "    sns.stripplot(x='Truth', y='PredProb', data=result, jitter=0.4, palette=['grey'], order=['-'], alpha=0.6, s=6)\n",
    "    ax.set_xlim(-1, 2); ax.set_ylabel('Prediction Probability'); ax.set_xlabel('Ground Truth')\n",
    "    ax.get_children()[0].set_hatch('//')\n",
    "    ax.get_children()[0].set_edgecolor('grey')\n",
    "    for idx in range(1, 6):\n",
    "        ax.get_children()[idx].set_color('grey')\n",
    "\n",
    "    # report statistics\n",
    "    print('p-value for + vs. -:')\n",
    "    print(ss.mannwhitneyu(result.loc[result['Truth'] == '+', 'PredProb'], result.loc[result['Truth'] == '-', 'PredProb']))\n",
    "    print('average:')\n",
    "    print(df_stat.mean(0))\n",
    "    print('95% cis:')\n",
    "    print(df_stat.std(0) / np.sqrt(10) * 1.96)\n",
    "    return df_stat, probas, truths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d650a0-1ed9-4481-83f4-7358d6fb2336",
   "metadata": {},
   "source": [
    "## Fetal Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe1096f-9e60-41b7-bad6-909a4a7e39a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains(':TYPE_1_INNATE_T'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = False\n",
    "# perform predictions with all\n",
    "df_stat_fetal, _, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca2edf8-ca69-4f92-a389-be07acd65ab1",
   "metadata": {},
   "source": [
    "## Fetal... --> COVID-19 and Adult Healthy Donors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34a70c1-8b84-4098-b018-6b7da3bfd929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_su2022_X.copy()\n",
    "X2 = X2.loc[~X2.index.str.endswith('nan')]\n",
    "X2 = X2.loc[~X2.index.str.endswith('CD8_Naive_14')]\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('CD8_Cytotoxic_3'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_covid, probas_covid, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fce84b-903b-4d44-8c39-dfafe4ec3669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_covid, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Adult PT and HD CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57092d2-7ddd-40d8-bbca-64969f1fdb09",
   "metadata": {},
   "source": [
    "## Fetal... --> Pan-Cancer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dfd58a-710d-46bd-80f7-042c99477091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the data to train on\n",
    "X1 = og_trb_suo2022_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y1 = pd.Series(X1.index.str.contains(':TYPE_1_INNATE_T'), index=X1.index)\n",
    "print(X1.shape[0], y1.sum(), y1.mean())\n",
    "\n",
    "# define the data to predict on\n",
    "X2 = og_trb_zheng2021_X.copy()\n",
    "# setup a mask for CD8+ cells\n",
    "y2 = pd.Series(X2.index.str.contains('KIR'), index=X2.index)\n",
    "print(X2.shape[0], y2.sum(), y2.mean())\n",
    "\n",
    "# define whether we are to predict on the complete data\n",
    "pred_on_all = True\n",
    "# perform predictions with all\n",
    "df_stat_tumor, probas_tumor, _ = interrogate_with_globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a335591-02ea-4ade-85a7-f9d5622b70c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the distribution\n",
    "df_plot = pd.concat(probas_tumor, axis=1).reset_index().melt(id_vars='index')\n",
    "df_plot[['sample','phenotype']] = df_plot['index'].str.split(':', expand=True)\n",
    "df_plot['value'] -= df_plot['value'].mean()\n",
    "df_plot['value'] /= df_plot['value'].std()\n",
    "fig, ax = plt.subplots(figsize=[5, 4]); ax.grid(False)\n",
    "order = df_plot.groupby('phenotype').mean(numeric_only=True)['value'].sort_values().index\n",
    "sns.barplot(x='phenotype', y='value', data=df_plot, ci=95, errwidth=1.5, linewidth=1.5, ax=ax, order=order,\n",
    "            capsize=0.3, errcolor='dodgerblue', edgecolor='dodgerblue', color='skyblue', saturation=1)\n",
    "ax.tick_params(axis='x', labelrotation=90)\n",
    "ax.axhline(0, color='k')\n",
    "ax.set_xlim(-1, len(order))\n",
    "ax.set(xlabel='Pan-Cancer CD8+ T Cell States', ylabel='Type I Innate Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c11f619-c2f3-4556-9e60-84f549088a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (base_py39)",
   "language": "python",
   "name": "base_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
